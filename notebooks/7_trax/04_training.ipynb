{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rgrouls/Library/Caches/pypoetry/virtualenvs/deep-learning-xB8KIJr7-py3.9/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py:228: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  interpolation: int = Image.BILINEAR,\n",
      "/Users/rgrouls/Library/Caches/pypoetry/virtualenvs/deep-learning-xB8KIJr7-py3.9/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py:295: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "/Users/rgrouls/Library/Caches/pypoetry/virtualenvs/deep-learning-xB8KIJr7-py3.9/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py:328: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  interpolation: int = Image.BICUBIC,\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "from src.models.build import summary\n",
    "from src.data import data_tools, make_dataset\n",
    "from src.models import tokenizer \n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "from trax.shapes import signature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first pull up the code we have used earlier to create a streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 12:20:37.349 | INFO     | src.data.make_dataset:get_imdb_data:96 - ../../data/raw/aclImdb already exists, skipping download\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3158.35it/s]\n",
      "100%|██████████| 25000/25000 [00:08<00:00, 3083.14it/s]\n",
      "2022-06-07 12:21:00.721 | INFO     | src.models.tokenizer:build_vocab:27 - Found 79808 tokens\n"
     ]
    }
   ],
   "source": [
    "import gin\n",
    "gin.parse_config_file(\"preprocessor.gin\")\n",
    "\n",
    "data_dir = \"../../data/raw\"\n",
    "# use the imdb text data\n",
    "trainpaths, testpaths = make_dataset.get_imdb_data(data_dir)\n",
    "traindataset = data_tools.TextDataset(paths=trainpaths)\n",
    "testdataset = data_tools.TextDataset(paths=testpaths)\n",
    "\n",
    "# build a corpus and vocab\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=10000)\n",
    "\n",
    "# use the preprocessor for cleaning\n",
    "preprocessor = tokenizer.Preprocessor(vocab=v, clean=tokenizer.clean)\n",
    "\n",
    "# wrap it up inside a streamer\n",
    "trainstream = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "\n",
    "teststream = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(trainstream)\n",
    "type(X), type(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works. However, we will have PyTorch Tensors.\n",
    "\n",
    "We could rewrite everything, but we could also cast it to numpy, because trax works fine with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cast():\n",
    "    def f(generator):\n",
    "        for x, y in generator:\n",
    "            yield x.numpy(), y.numpy()\n",
    "\n",
    "    return lambda g: f(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a functionwrapper, that returns a function that has a generator g as input.\n",
    "We can yield a first sample from the generator, cast it to numpy, and yield that again. \n",
    "\n",
    "This way we will have chained two generators. We can use `trax.data.Serial` to chain generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pipeline = trax.data.Serial(Cast())\n",
    "trainpipe = data_pipeline(trainstream)\n",
    "testpipe = data_pipeline(teststream)\n",
    "X, y = next(trainpipe)\n",
    "type(X), type(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the GRU model, the GRU layer will output (batch, sequence, dimension).\n",
    "We could do two thing here:\n",
    "1. Simply take the last timestep of the sequence\n",
    "2. Take the average of the sequence\n",
    "\n",
    "Let's implement both as a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Last():\n",
    "    return tl.Fn(\"Last\", lambda x: x[:, -1, :], n_out=1)\n",
    "\n",
    "def AvgLast():\n",
    "    return tl.Fn(\"AvgLast\", lambda x: x.mean(axis=-1), n_out=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap this all into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape(\"bs->bd\")\n",
    "def EmbGRU(vocab_size: int, d_feature: int, d_out: int):\n",
    "    model = cb.Serial(\n",
    "        tl.Embedding(vocab_size=vocab_size, d_feature=d_feature),\n",
    "        tl.GRU(n_units=d_feature),\n",
    "        tl.BatchNorm(),\n",
    "        AvgLast(),\n",
    "        tl.Dense(d_out),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/Users/rgrouls/Library/Caches/pypoetry/virtualenvs/deep-learning-xB8KIJr7-py3.9/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3710: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"zeros\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_10002_128 (32, 100)          ( int32 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) BatchNorm           (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(3) AvgLast             (32, 100, 128)     (float32) | (32, 100)          (float32)\n",
      "(4) Dense_2             (32, 100)          (float32) | (32, 2)            (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 2), dtype:float32}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EmbGRU(vocab_size=len(v), d_feature=128, d_out=2)\n",
    "model.init_weights_and_state(signature(X))\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to train, we will need a loss function. Let's pick the CategoryCrossEntropy, which is the same as the CrossEntropy we have been using with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.69606143, dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(X)\n",
    "loss = tl.CategoryCrossEntropy()\n",
    "loss((yhat, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's add accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.53125, dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = tl.CategoryAccuracy()\n",
    "acc((yhat, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's check the accuracy to be sure this does what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([False,  True, False,  True, False, False,  True, False,\n",
       "              True,  True,  True,  True, False,  True, False, False,\n",
       "             False,  True,  True, False,  True, False,  True, False,\n",
       "              True, False,  True,  True, False, False,  True,  True],            dtype=bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "pred = jnp.argmax(yhat, axis=-1)\n",
    "correct = jnp.equal(pred, y)\n",
    "correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.53125, dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.sum() / len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that works as expected.\n",
    "\n",
    "We have been talking about learning rate schedules. Trax has implemented some of them too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1547280d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trax.supervised.lr_schedules import warmup_and_rsqrt_decay\n",
    "\n",
    "lr = warmup_and_rsqrt_decay(100, 0.01)\n",
    "steps = jnp.arange(1200)\n",
    "y = [lr(x) for x in steps]\n",
    "plt.plot(steps, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train everything, we can wrap this in a train and eval task, and combine that in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 12:31:21.528 | INFO     | src.data.data_tools:dir_add_timestamp:213 - Logging to ../../models/trax/20220607-1231\n"
     ]
    }
   ],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "model = EmbGRU(vocab_size=len(v), d_feature=128, d_out=2)\n",
    "log_dir = \"../../models/trax\"\n",
    "log_dir = data_tools.dir_add_timestamp(log_dir)\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=trainpipe,\n",
    "    loss_layer=tl.CategoryCrossEntropy(),\n",
    "    optimizer=trax.optimizers.Adam(),\n",
    "    lr_schedule=lr\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=testpipe, metrics=[tl.CategoryAccuracy(), tl.CategoryCrossEntropy()], n_eval_batches=25\n",
    ")\n",
    "\n",
    "loop = training.Loop(\n",
    "    model,\n",
    "    train_task,\n",
    "    eval_tasks=[eval_task],\n",
    "    output_dir=log_dir,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trax expects streamers. They can go on forever, so let's test a 1000 batches: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 1379148\n",
      "Step      1: Ran 1 train steps in 2.92 secs\n",
      "Step      1: train CategoryCrossEntropy |  0.70305592\n",
      "Step      1: eval      CategoryAccuracy |  0.50625000\n",
      "Step      1: eval  CategoryCrossEntropy |  0.71088120\n",
      "\n",
      "Step    100: Ran 99 train steps in 6.31 secs\n",
      "Step    100: train CategoryCrossEntropy |  0.66260082\n",
      "Step    100: eval      CategoryAccuracy |  0.72875000\n",
      "Step    100: eval  CategoryCrossEntropy |  0.52359872\n",
      "\n",
      "Step    200: Ran 100 train steps in 6.58 secs\n",
      "Step    200: train CategoryCrossEntropy |  0.49283358\n",
      "Step    200: eval      CategoryAccuracy |  0.76250000\n",
      "Step    200: eval  CategoryCrossEntropy |  0.47756310\n",
      "\n",
      "Step    300: Ran 100 train steps in 6.30 secs\n",
      "Step    300: train CategoryCrossEntropy |  0.44162586\n",
      "Step    300: eval      CategoryAccuracy |  0.77500000\n",
      "Step    300: eval  CategoryCrossEntropy |  0.45299261\n",
      "\n",
      "Step    400: Ran 100 train steps in 6.31 secs\n",
      "Step    400: train CategoryCrossEntropy |  0.40324441\n",
      "Step    400: eval      CategoryAccuracy |  0.79750000\n",
      "Step    400: eval  CategoryCrossEntropy |  0.41134120\n",
      "\n",
      "Step    500: Ran 100 train steps in 6.25 secs\n",
      "Step    500: train CategoryCrossEntropy |  0.40000734\n",
      "Step    500: eval      CategoryAccuracy |  0.80250000\n",
      "Step    500: eval  CategoryCrossEntropy |  0.39222789\n",
      "\n",
      "Step    600: Ran 100 train steps in 6.63 secs\n",
      "Step    600: train CategoryCrossEntropy |  0.60922682\n",
      "Step    600: eval      CategoryAccuracy |  0.65750000\n",
      "Step    600: eval  CategoryCrossEntropy |  0.65039429\n",
      "\n",
      "Step    700: Ran 100 train steps in 6.47 secs\n",
      "Step    700: train CategoryCrossEntropy |  0.55530685\n",
      "Step    700: eval      CategoryAccuracy |  0.79625000\n",
      "Step    700: eval  CategoryCrossEntropy |  0.46318097\n",
      "\n",
      "Step    800: Ran 100 train steps in 6.54 secs\n",
      "Step    800: train CategoryCrossEntropy |  0.42458925\n",
      "Step    800: eval      CategoryAccuracy |  0.76625000\n",
      "Step    800: eval  CategoryCrossEntropy |  0.49637792\n",
      "\n",
      "Step    900: Ran 100 train steps in 6.46 secs\n",
      "Step    900: train CategoryCrossEntropy |  0.55936164\n",
      "Step    900: eval      CategoryAccuracy |  0.71125000\n",
      "Step    900: eval  CategoryCrossEntropy |  0.56380245\n",
      "\n",
      "Step   1000: Ran 100 train steps in 6.68 secs\n",
      "Step   1000: train CategoryCrossEntropy |  0.47688270\n",
      "Step   1000: eval      CategoryAccuracy |  0.79500000\n",
      "Step   1000: eval  CategoryCrossEntropy |  0.43687704\n"
     ]
    }
   ],
   "source": [
    "loop.run(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is pretty easy to add an additional 200 steps. Trax will pick up where it left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step   1100: Ran 100 train steps in 6.31 secs\n",
      "Step   1100: train CategoryCrossEntropy |  0.37939116\n",
      "Step   1100: eval      CategoryAccuracy |  0.79125000\n",
      "Step   1100: eval  CategoryCrossEntropy |  0.45956976\n",
      "\n",
      "Step   1200: Ran 100 train steps in 6.42 secs\n",
      "Step   1200: train CategoryCrossEntropy |  0.34051177\n",
      "Step   1200: eval      CategoryAccuracy |  0.80500000\n",
      "Step   1200: eval  CategoryCrossEntropy |  0.44571803\n"
     ]
    }
   ],
   "source": [
    "loop.run(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see that our model works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.8125, dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(testpipe)\n",
    "yhat = model(X)\n",
    "acc = tl.CategoryAccuracy()\n",
    "acc((yhat, y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
