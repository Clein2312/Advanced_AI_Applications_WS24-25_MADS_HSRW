{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import data_tools\n",
    "from pathlib import Path\n",
    "import gin\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from src.models import rnn_models, train_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterators\n",
    "We will be using an interesting dataset. [link](https://tev.fbk.eu/resources/smartwatch)\n",
    "\n",
    "From the site:\n",
    "> The SmartWatch Gestures Dataset has been collected to evaluate several gesture recognition algorithms for interacting with mobile applications using arm gestures. Eight different users performed twenty repetitions of twenty different gestures, for a total of 3200 sequences. Each sequence contains acceleration data from the 3-axis accelerometer of a first generation Sony SmartWatch™, as well as timestamps from the different clock sources available on an Android device. The smartwatch was worn on the user's right wrist. \n",
    "\n",
    "# 1.1 Iterator design pattern\n",
    "This is a nice opportunity to create our own custom iterator. First, let's look at the simplified design pattern for an iterator.\n",
    "This introduces two additional dunder methods, used in forloops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "class BaseIterator:\n",
    "  def __init__(self, n: int):\n",
    "    self.n = n\n",
    "    # we generate some dummy data\n",
    "    self.data = [*range(self.n)]\n",
    "\n",
    "  def __iter__(self):\n",
    "    # startindex; this makes the first index used effectively 0,\n",
    "    # because -1 is smaller than the dataset so the first\n",
    "    # thing that will happen in __next__ is to add +1\n",
    "    self.idx = -1\n",
    "    # we return the full object when iter() is called\n",
    "    return self\n",
    "\n",
    "  def __next__(self):\n",
    "    # for every iteration, __next__ is called\n",
    "    # as long as the idx is not bigger than the data\n",
    "    # we need to do -1, because we will increase idx directly after this\n",
    "    if self.idx < len(self.data) - 1:\n",
    "      self.idx += 1\n",
    "      return self.data[self.idx]\n",
    "    else:\n",
    "      raise StopIteration\n",
    "\n",
    "myclass = BaseIterator(n=5)\n",
    "myiter = iter(myclass) # this calles the __iter__ method and sets idx to -1\n",
    "\n",
    "for x in myiter: # this calls the __next__ method\n",
    "  print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how `__iter__` returns `self` with the startsettings (`idx=-1`).\n",
    "Every time we call `__next__`, (implicitly in a forloop or explicitly with `next()`) the idx is increased by +1.\n",
    "\n",
    "If you keep calling `next()`, you will eventually get a `StopIteration` error but a forloop will wait for that and stop the loop gracefully.\n",
    "\n",
    "## 1.2 Iterator implementation\n",
    "Now, we extend this pattern to our dataset. We will use what we have seen before with the images (lesson 1, 02_datagenerators.ipynb and 03_dataloader.ipynb): we load the paths, and use these to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "# the base dataset that provides the boilerplate code\n",
    "class BaseDataset:\n",
    "    def __init__(self, paths: List[Path]) -> None:\n",
    "        self.paths = paths\n",
    "        random.shuffle(self.paths)\n",
    "        self.dataset = []\n",
    "        self.process_data()\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        # this needs to be implemented if you want to use the BaseDataset\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Tensor, int]:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "# the TSDataset, that inherits all the boilerplate code\n",
    "# and implements a process_data method for this dataset\n",
    "class TSDataset(BaseDataset):\n",
    "    # this is called inheritance.\n",
    "    # we get all the methods from the BaseDataset for free\n",
    "    # Only thing we need to do is implement the process_data method\n",
    "    def process_data(self) -> None:\n",
    "        for file in tqdm(self.paths):\n",
    "            x_ = np.genfromtxt(file)[:, 3:]\n",
    "            x = torch.tensor(x_).type(torch.float32)\n",
    "            y = torch.tensor(int(file.parent.name) - 1)\n",
    "            self.dataset.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseDataset, batchsize: int):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        self.index = 0\n",
    "        self.index_list = torch.randperm(len(self.dataset))\n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        for _ in range(self.batchsize):\n",
    "            # the design trick with the index_list and index allows us to shuffle the\n",
    "            # index_list every time we call __iter__\n",
    "            # withouth shuffling the actual data\n",
    "            x, y = self.dataset[int(self.index_list[self.index])]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            # the index will signal the end of the dataset in the __next__ method \n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            # this stops the iteration just before the index\n",
    "            # would reach the end of the length of the dataset\n",
    "            X, Y = self.batchloop()\n",
    "            return X, Y\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    # again, we inherit everything from the baseclass\n",
    "    def __init__(self, dataset: BaseDataset, batchsize: int) -> None:\n",
    "        # we initialize the super class BaseDataIterator\n",
    "        # we now have everything the BaseDataIterator can do, for free\n",
    "        super().__init__(dataset, batchsize)\n",
    "    \n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            # we just want to add padding\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference with the pattern we used before, is that this pattern will stop after the last item is spit out.\n",
    "The generator from the first lesson will go on forever, due to the `while True` loop.\n",
    "\n",
    "## 1.3 Train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data/external/gestures-dataset/\").resolve()\n",
    "\n",
    "# get all paths with the .txt extension\n",
    "formats = [\".txt\"]\n",
    "paths = [path for path in data_tools.walk_dir(data_dir) if path.suffix in formats]\n",
    "# make a train-test split\n",
    "split = 0.8\n",
    "idx = int(len(paths) * split)\n",
    "trainpaths = paths[:idx]\n",
    "testpaths = paths[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2600/2600 [00:02<00:00, 1276.56it/s]\n",
      "100%|██████████| 651/651 [00:00<00:00, 1510.12it/s]\n"
     ]
    }
   ],
   "source": [
    "traindataset = TSDataset(trainpaths)\n",
    "testdataset = TSDataset(testpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "trainloader = PaddedDatagenerator(traindataset, batchsize=batchsize)\n",
    "testloader = PaddedDatagenerator(testdataset, batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17, 3]), tensor(13))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[1]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 81, 651, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset), len(trainloader), len(testdataset), len(testloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the lenght mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make sense of the shape?\n",
    "What does it mean that the shapes are sometimes (32, 27, 3), but a second time might look like (32, 30, 3)? In other words, the second (or first, if you insist on starting at 0) dimension changes. Why is that? How does the model handle this? Do you think this is already padded, or still has to be padded?\n",
    "\n",
    "\n",
    "# 2 Excercises\n",
    "Lets test a basemodel, and try to improve upon that.\n",
    "\n",
    "Fill the gestures.gin file with relevant settings for `input_size`, `hidden_size`, `num_layers` and `horizon` (which, in our case, will be the number of classes...)\n",
    "\n",
    "As a rule of thumbs: start lower than you expect to need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"gestures.gin\")\n",
    "model = rnn_models.BaseRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 3, 'hidden_size': 128, 'num_layers': 3, 'horizon': 20}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.get_bindings(\"BaseRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 10,\n",
       " 'learning_rate': 0.001,\n",
       " 'optimizer': torch.optim.adam.Adam,\n",
       " 'loss_fn': CrossEntropyLoss()}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.get_bindings(\"trainloop\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model. What is the output shape you need? Remember, we are doing classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0625)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import metrics\n",
    "\n",
    "accuracy = metrics.Accuracy()\n",
    "accuracy(y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy? What would you expect from blind guessing?\n",
    "\n",
    "Check shape of `y` and `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 20]), torch.Size([32]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the output of yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0022,  0.0354,  0.0403, -0.0449, -0.0454, -0.0696,  0.0635, -0.0304,\n",
       "         0.0328,  0.0429, -0.2080, -0.0179,  0.0426,  0.1205, -0.1144, -0.0249,\n",
       "        -0.0645, -0.1948, -0.0691,  0.0210], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense to you? If you are unclear, go back to the classification problem with the MNIST, where we had 10 classes.\n",
    "\n",
    "We have a classification problem, so we need Cross Entropy Loss.\n",
    "Remember, [this has a softmax built in](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0038, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(yhat, y)\n",
    "accuracy = metrics.Accuracy()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:32:35.544 | INFO     | src.data.data_tools:dir_add_timestamp:129 - Logging to modellog/20230522-1132\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.16it/s]\n",
      "2023-05-22 11:32:41.889 | INFO     | src.models.train_model:trainloop:186 - Epoch 0 train 2.5539 test 2.4480 metric ['0.1406']\n",
      "2023-05-22 11:32:41.890 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (2.448049 --> 2.448049). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.44it/s]\n",
      "2023-05-22 11:32:47.406 | INFO     | src.models.train_model:trainloop:186 - Epoch 1 train 1.9799 test 1.9705 metric ['0.2828']\n",
      "2023-05-22 11:32:47.407 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (1.970468 --> 1.970468). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.88it/s]\n",
      "2023-05-22 11:32:52.566 | INFO     | src.models.train_model:trainloop:186 - Epoch 2 train 1.5517 test 1.6771 metric ['0.4031']\n",
      "2023-05-22 11:32:52.567 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (1.677106 --> 1.677106). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.42it/s]\n",
      "2023-05-22 11:32:58.189 | INFO     | src.models.train_model:trainloop:186 - Epoch 3 train 1.1349 test 1.2021 metric ['0.5422']\n",
      "2023-05-22 11:32:58.190 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (1.202088 --> 1.202088). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.86it/s]\n",
      "2023-05-22 11:33:04.311 | INFO     | src.models.train_model:trainloop:186 - Epoch 4 train 0.8394 test 0.9292 metric ['0.6484']\n",
      "2023-05-22 11:33:04.312 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (0.929172 --> 0.929172). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.00it/s]\n",
      "2023-05-22 11:33:10.347 | INFO     | src.models.train_model:trainloop:186 - Epoch 5 train 0.5643 test 0.7316 metric ['0.7203']\n",
      "2023-05-22 11:33:10.349 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (0.731577 --> 0.731577). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 16.03it/s]\n",
      "2023-05-22 11:33:15.943 | INFO     | src.models.train_model:trainloop:186 - Epoch 6 train 0.3496 test 0.7837 metric ['0.7953']\n",
      "2023-05-22 11:33:15.944 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 1 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:06<00:00, 12.95it/s]\n",
      "2023-05-22 11:33:22.908 | INFO     | src.models.train_model:trainloop:186 - Epoch 7 train 0.2302 test 0.6952 metric ['0.8031']\n",
      "2023-05-22 11:33:22.909 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (0.695169 --> 0.695169). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.13it/s]\n",
      "2023-05-22 11:33:28.843 | INFO     | src.models.train_model:trainloop:186 - Epoch 8 train 0.1795 test 0.4810 metric ['0.8609']\n",
      "2023-05-22 11:33:28.844 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (0.480999 --> 0.480999). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.42it/s]\n",
      "2023-05-22 11:33:34.649 | INFO     | src.models.train_model:trainloop:186 - Epoch 9 train 0.1149 test 0.5634 metric ['0.8547']\n",
      "2023-05-22 11:33:34.650 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 1 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.97it/s]\n",
      "2023-05-22 11:33:40.192 | INFO     | src.models.train_model:trainloop:186 - Epoch 10 train 0.0915 test 0.5187 metric ['0.8719']\n",
      "2023-05-22 11:33:40.193 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 2 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.80it/s]\n",
      "2023-05-22 11:33:45.916 | INFO     | src.models.train_model:trainloop:186 - Epoch 11 train 0.0839 test 0.6055 metric ['0.8562']\n",
      "2023-05-22 11:33:45.917 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 3 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.30it/s]\n",
      "2023-05-22 11:33:51.992 | INFO     | src.models.train_model:trainloop:186 - Epoch 12 train 0.0659 test 0.3708 metric ['0.9078']\n",
      "2023-05-22 11:33:51.993 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (0.370808 --> 0.370808). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:06<00:00, 11.66it/s]\n",
      "2023-05-22 11:33:59.793 | INFO     | src.models.train_model:trainloop:186 - Epoch 13 train 0.0491 test 0.3620 metric ['0.9172']\n",
      "2023-05-22 11:33:59.794 | INFO     | src.models.train_model:save_checkpoint:296 - Validation loss (0.361963 --> 0.361963). Saving modellog/20230522-1132/checkpoint.pt ...\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 13.63it/s]\n",
      "2023-05-22 11:34:06.437 | INFO     | src.models.train_model:trainloop:186 - Epoch 14 train 0.0673 test 0.5383 metric ['0.8688']\n",
      "2023-05-22 11:34:06.439 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 1 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.56it/s]\n",
      "2023-05-22 11:34:11.917 | INFO     | src.models.train_model:trainloop:186 - Epoch 15 train 0.0461 test 0.4547 metric ['0.9078']\n",
      "2023-05-22 11:34:11.918 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 2 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.00it/s]\n",
      "2023-05-22 11:34:18.015 | INFO     | src.models.train_model:trainloop:186 - Epoch 16 train 0.0373 test 0.6461 metric ['0.8703']\n",
      "2023-05-22 11:34:18.017 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 3 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.25it/s]\n",
      "2023-05-22 11:34:23.942 | INFO     | src.models.train_model:trainloop:186 - Epoch 17 train 0.0461 test 0.6252 metric ['0.8797']\n",
      "2023-05-22 11:34:23.943 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 4 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.49it/s]\n",
      "2023-05-22 11:34:29.415 | INFO     | src.models.train_model:trainloop:186 - Epoch 18 train 0.0245 test 0.4569 metric ['0.8953']\n",
      "2023-05-22 11:34:29.416 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 5 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.49it/s]\n",
      "2023-05-22 11:34:35.298 | INFO     | src.models.train_model:trainloop:186 - Epoch 19 train 0.0206 test 0.4475 metric ['0.9125']\n",
      "2023-05-22 11:34:35.299 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 6 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.39it/s]\n",
      "2023-05-22 11:34:40.820 | INFO     | src.models.train_model:trainloop:186 - Epoch 20 train 0.0117 test 0.4281 metric ['0.8953']\n",
      "2023-05-22 11:34:40.821 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 7 out of 8\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.20it/s]\n",
      "2023-05-22 11:34:47.363 | INFO     | src.models.train_model:trainloop:186 - Epoch 21 train 0.0105 test 0.5596 metric ['0.8938']\n",
      "2023-05-22 11:34:47.364 | INFO     | src.models.train_model:__call__:283 - EarlyStopping counter: 8 out of 8\n",
      "2023-05-22 11:34:47.366 | INFO     | src.models.train_model:trainloop:192 - Interrupting loop due to early stopping patience.\n",
      "2023-05-22 11:34:47.368 | INFO     | src.models.train_model:trainloop:194 - retrieving best model.\n",
      " 42%|\u001b[38;2;30;71;6m████▏     \u001b[0m| 21/50 [02:11<03:02,  6.28s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument 'pytorch_model' should be a torch.nn.Module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 36\u001b[0m\n\u001b[1;32m     20\u001b[0m model \u001b[39m=\u001b[39m rnn_models\u001b[39m.\u001b[39mGRUmodel()\n\u001b[1;32m     22\u001b[0m model, testloss \u001b[39m=\u001b[39m train_model\u001b[39m.\u001b[39mtrainloop(\n\u001b[1;32m     23\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m     metrics\u001b[39m=\u001b[39m[accuracy],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     tunewriter\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmlflow\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgin\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m mlflow\u001b[39m.\u001b[39;49mpytorch\u001b[39m.\u001b[39;49mlog_model(model, \u001b[39m\"\u001b[39;49m\u001b[39mgru\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     38\u001b[0m tag \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m modelpath \u001b[39m=\u001b[39m modeldir \u001b[39m/\u001b[39m (tag \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deep-learning-HUU8cknU-py3.8/lib/python3.8/site-packages/mlflow/pytorch/__init__.py:323\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(pytorch_model, artifact_path, conda_env, code_paths, pickle_module, registered_model_name, signature, input_example, await_registration_for, requirements_file, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39mLog a PyTorch model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39m    PyTorch logged models\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    322\u001b[0m pickle_module \u001b[39m=\u001b[39m pickle_module \u001b[39mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[0;32m--> 323\u001b[0m \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    324\u001b[0m     artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[1;32m    325\u001b[0m     flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49mpytorch,\n\u001b[1;32m    326\u001b[0m     pytorch_model\u001b[39m=\u001b[39;49mpytorch_model,\n\u001b[1;32m    327\u001b[0m     conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[1;32m    328\u001b[0m     code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[1;32m    329\u001b[0m     pickle_module\u001b[39m=\u001b[39;49mpickle_module,\n\u001b[1;32m    330\u001b[0m     registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[1;32m    331\u001b[0m     signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m    332\u001b[0m     input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[1;32m    333\u001b[0m     await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[1;32m    334\u001b[0m     requirements_file\u001b[39m=\u001b[39;49mrequirements_file,\n\u001b[1;32m    335\u001b[0m     extra_files\u001b[39m=\u001b[39;49mextra_files,\n\u001b[1;32m    336\u001b[0m     pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[1;32m    337\u001b[0m     extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[1;32m    338\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    339\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    340\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deep-learning-HUU8cknU-py3.8/lib/python3.8/site-packages/mlflow/models/model.py:547\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m run_id \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[1;32m    546\u001b[0m mlflow_model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(artifact_path\u001b[39m=\u001b[39martifact_path, run_id\u001b[39m=\u001b[39mrun_id, metadata\u001b[39m=\u001b[39mmetadata)\n\u001b[0;32m--> 547\u001b[0m flavor\u001b[39m.\u001b[39;49msave_model(path\u001b[39m=\u001b[39;49mlocal_path, mlflow_model\u001b[39m=\u001b[39;49mmlflow_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    548\u001b[0m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39martifact_path)\n\u001b[1;32m    549\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deep-learning-HUU8cknU-py3.8/lib/python3.8/site-packages/mlflow/pytorch/__init__.py:505\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(pytorch_model, path, conda_env, mlflow_model, code_paths, pickle_module, signature, input_example, requirements_file, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m pickle_module \u001b[39m=\u001b[39m pickle_module \u001b[39mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pytorch_model, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpytorch_model\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should be a torch.nn.Module\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(path)\n\u001b[1;32m    507\u001b[0m _validate_and_prepare_target_save_path(path)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'pytorch_model' should be a torch.nn.Module"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"../../models/gestures/\").resolve()\n",
    "# gin.parse_config_file(\"gestures.gin\")\n",
    "gin.parse_config_file(\"gestures_gru.gin\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"convnet\")\n",
    "    mlflow.set_tag(\"dev\", \"raoul\")\n",
    "    # mlflow.log_params(gin.get_bindings(\"BaseRNN\"))\n",
    "    mlflow.log_params(gin.get_bindings(\"GRUmodel\"))\n",
    "    mlflow.log_params(gin.get_bindings(\"trainloop\"))\n",
    "    mlflow.log_param(\"datadir\", f\"{data_dir}\")\n",
    "    mlflow.log_param(\"batchsize\", f\"{batchsize}\")\n",
    "\n",
    "    # model = rnn_models.BaseRNN()\n",
    "    model = rnn_models.GRUmodel()\n",
    "\n",
    "    model, testloss = train_model.trainloop(\n",
    "        model=model,\n",
    "        metrics=[accuracy],\n",
    "        train_dataloader=trainloader,\n",
    "        test_dataloader=testloader,\n",
    "        log_dir=\"modellog\",\n",
    "        train_steps=len(trainloader),\n",
    "        eval_steps=len(testloader),\n",
    "        patience=3,\n",
    "        factor=0.5,\n",
    "        early_stopping_patience=8,\n",
    "        early_stopping_save=True,\n",
    "        tunewriter=[\"tensorboard\", \"mlflow\", \"gin\"]\n",
    "    )\n",
    "    mlflow.pytorch.log_model(model, \"gru\")\n",
    "\n",
    "    tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    modelpath = modeldir / (tag + \"model.pt\")\n",
    "    torch.save(model, modelpath)\n",
    "    mlflow.log_artifact(local_path=modelpath, artifact_path=\"pytorch_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercises:\n",
    "\n",
    "- improve the RNN model\n",
    "- test different things. What works? What does not?\n",
    "- experiment with either GRU or LSTM layers, create your own models + ginfiles. \n",
    "- experiment with adding Conv1D layers.\n",
    "\n",
    "You should be able to get above 90% accuracy with the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c41bdaf5373703b03bba2d9bd89c97dc8ee5add9f1112e039ff04603b8e2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
