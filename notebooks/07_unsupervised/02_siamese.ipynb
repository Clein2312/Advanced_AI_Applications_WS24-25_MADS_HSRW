{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from trax import layers as tl\n",
    "from trax.shapes import signature\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.models.build import summary\n",
    "from pathlib import Path\n",
    "from src.data import data_tools\n",
    "\n",
    "from src.settings import SiameseSettings\n",
    "\n",
    "settings = SiameseSettings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.80M/3.80M [00:01<00:00, 3.68MiB/s]\n"
     ]
    }
   ],
   "source": [
    "url = settings.url\n",
    "data_dir = settings.data_dir\n",
    "\n",
    "data_tools.get_file(data_dir, settings.file, url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "paths, _ = data_tools.iter_valid_paths(data_dir / settings.training, formats=[\".pgm\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at a file.\n",
    "This are faces of 40 subjects, and every subject has 10 photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (112, 92)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABwCAAAAAC26kjJAAAb6ElEQVR4nCXRyc6t6XUQ4LXW237N7v72dK46dpWryrHT2IkTIBMiFEQmGIlBBgyQkBhxJdwBN8AACQkJkBgkAjsOIcTgmLicOOVydaepc87f7r2/7m3WWgxyC8+Dp5ZJkIQEAEGpukoxdi5e3M1dZxsTiHTY+Ao5eJwdLw2PVCvujf9c7/VY2QgogiJUC9Uw1SNAE1XVGlUEEmJEISpGKm2nuHmSbo+PpIt2tCbOu1lXYJ3Nm3m1WvhiHmHlkj23ZqYDI6AigBAKIhiFHmsQJMALyr5YUFDDiGIU19w/Pr8et7zGDohdx0FHE8QjCqMTFcg4RDyGIY/L3XIFpgL4SQEVBQUB2TKggrXVqStOlYBQ0SW/bt/W13getYvVcdNqOKxOR19XxSlPgAZEnFcAXs2mDTXXxWCubSpGFEiJEQGUgO3fcZBSJVex268vv6ZvXBO9bjy0YGvpBoB4v2mELCnanE1jFSn7g41TzPZrV8/Wg7PSLQVQgQDRCKIiW1MsqmEANJXs9PjxLl8vX3epb2A8EdOWBeau4x5CPbZg2SiGGqQqdkkOFNb23h43nszeF1cnpwCogIoo3jIJIhshBoPhvdXwZli9PW1WHrqpHY1iQz3FHAPFRFydkJhSlk58Pt+HNU+hx6/EN13R0s1um5NYBkAQpEqipNWJKCn1v9tmn9aPo/XN0M8PJGYhxVKtd02OW+NbTxgQqA++uAI743dozJYuS9mctk5ptXWKCAAIANaooq3gK7jTpzkXeLhqhjNvNsV7LI1Rtv4EnF+Gra2I6nKUFhSky45YQymejmr9cS4Nhjdz2MkNEFtGdoQIqogV4auP11NYn25c1XXgmLYVU5NdiGdNybHZmQ77xZTWWfJAnizakBbqHW+B66WDtskbSZkuYrGMSmqBBBDZ+N37vIQGgm1y58VFEs8rCsU3IiaA2YJW42xITVZhjoplldYwtsrQ5CQXX2hu5s2ktd+Zo1FAJqwEiEHf/0ag6kxnAqzdguRUCMga24rUmT1HsifWWWqtD55InO6xT12I0hoM7ZIeZ87dbr31N9N2DYTqCAyAg+bJW7ujD11MzdI0JqRYIS8FmWxJVVoDjaiN6rvepeK190HVIzZTrLZAz7tmcTuTZ9k1uye035yIg0qCbJzpf6VLUFbBIfUerSdTnecMi8kZ46bFCQDFsEAXYyTTOc3g0TYe2sJ7OUXTWHtqZT+LbB/HuTtlY4iA+9w+WmMNSBI6T5KAnIKAtWjIF2v9kotxCqbaAjWu0DPZPq37OVpP1MzaOt6R+AupC3FpH4IJHQEhAu7k3DRQm2gJoVGZaZWNHcyJGGkslqxqNdnhJsiiHoTqpCABjBZHGnjbCq9rExr7FddiXnL/ZH/eNJ4EyCxvd6s59IqtRItlv66wsGZW8KmsyI2mSZgLKQ7BYpMOHv0EGzZUhGdnYzwwBuyjNo/MUpe5hKd5u92Rqc3UnzXLRABsqGPRS5MSce5z2qOI8bM1Q82MzinXsZRAHrNJkYSEWMCE1kSMBG5Dlx1jGSeM2z4+IkE2u5Zm0xK4Yih66LwbA2nxPtx5M2vK4PyIAtZvA+mQw7Klzi+0NICt1dbUPgixWEt4bkUpj0M/hERo0u7B+WgCdiYbRTS2u4p9tI2JXieT9otzk9HcAg2z1gyEpGKhTkUnzyYaJO4sBRqyM2O3MURYZVh9tCeL5uytBbBYQ9TuXIfn8zZEqdhgduvqcWxMH9tzq1pnvoN5GISmiLMoJCeTFHW+hsaUeOjAlYelLqlJr7vTkaRuTwgbVjc3DfRxtYqlLYguN5zbaFJjmBDWXRL1OvemxeCmkqSvKt4hLzxjXqytHT+aXa/20jgtvfv8AyXNm/YuTKZlk1aeqnSvmGb0XUCqCZSgVUmFl2LUe2cYHY6e8lCcARIx5IqoTgqwtOpsMQ9YsTYtvnqflInNJBycIWuOThZtk2VrHHszF9NGM1tDU56KJGE/k6dqDRkxhY73hSs2hgBtwp4bXwLgytrsc3vfU+eyX0xHqsmbiaAcfVGFAsA2rgDVQsPohRuHKLjgjBKnw2BFg1gGR6rNqjVJYjtHKy3qWoGWsxQ+J3brJiYbJ2M30lgsYJm6PGByGtpGqhSvEZE9Oz0iOIxLmwczGs7immj9HMUhmxU2pGC9+NNtcGzck3vSEGSrcyS7tdYPsyrhYoxNxIpijSqp915idQ6bDhOWLvueJgVhTJBdrCPL5FLCfjAtW+89NR71/HeoywhlRSX64nWyrGbew4QNVytVVXhKmXNx4KCwpJLmoUonsiaxoI3R4sRW2yBUWxsMCFU9LnbavfqO3Z+m9dWqEnk/ECSgOrFNkbCIjF1RRUxoCpO1y4y+0hyKkiRSqs4fgBWHde1GbWbP6iutDnm953mt188t+81VWTxFN+/PucZhLGGqLIQzUYLsjc7Lyoq566vR7E2phhclVmCXDQZgw+pbnPrqHaaGafYaspcu0dm1v9uADdGPrr3G/PyYl9vjcHOccAJkzCkDzVMexoMx1krWNHCuMiN6SZlYCKywRfRjtBid7dQ4ddhTtsfLfCbaKpZ68rqUm+cN7mZM2JpmP62rgDgzdliXIEtmS0sVUgVjloiJLOvQugoZtTGzoMRsNs/s+jbQ6jrbcnjv/POTOB9nzPPAz/EgrHUybx4MSrM1VJ3l0TEdTabFuSXHCmCtJK5MVDAwIbuaVqwLoZu0h2Ks3QRHdtqa2Q7PhpINEZitmzLvuZT2Y0vg1ucxs9i6UYRUBTNVZWUkn0En7rMu3mRDmWxuunKyGHfsyCTfKvWjtdvlr0o59U6CAd0nXryuS0mZNRzdomvg6lxCYzjnkJNXAnC6pGFRlytjsp3GoQOGtUl2MNGCkhCkrdgn8OLzB7+5ezkeLjcnb/YtVkqpvO3un7sZWA/H1tC0Ic/Ecxi4JMOmgammYb+r96Z4DNm0TiHy5t5qRQcU+8VL2RT7ROBn37n84S3g23p1mO49zk1va3jvySf7QHzvl4bcBqkolDovVXxoDu0onJaxLP3+LIU5VFetxmxNRTU1ij3TVP3Kmt/7t98++bndvNys98f1PkTAmu7t3cvoNrkEf29p/cRQ2y8pDOUwhcFRcc1ir5Vmf20WcxtgWK/AgmKBvFnEUfrK69LeP7Z/T8bvvvAIF5TmuYNwOAPZ2sndvwjr0OTlJHfvrAHIGUpNoTFD5YC5cmqQauGrOG/q5jqfdmM8ns9es29TdIudndKvv3jXD8YbNyZv9qfNeUjjywX1yVvzszd7u3nmzrauD2zJdl1c6zAsZT8M+6WOr8rddKdpkpt9n0pqZyIxHCYosWbVY7Jv//ffeP1Lktak90a/McfmJaxigLS/Xs2Jj0/f+dJ8UwmiFjbRRvRQkdG6tCNUiNPi6t7fuvQgVXGQcTWD1pN9Xwt8Zl9M7/23JGhXjy+SP+PtF9tdvYupW9PzYxQ4/qrevHh/pmBV7WCv173jwoKCtivl6E5Vltq2V+3VeTobMtEYoAbHQab+pf352tzG27de4+9D2E70ovAwXKnfWjmFEYbz/oM/udqdC2pTp+HgLofC6Nmw/eqT/PLmJkd8orkI7buw7+47xlpqm1+8V6QaK5cH9vl7/+67Z8zuMKXGvDykW92zb+DcKyyntrkfVyEa4Zz1uokSF4XOHn+5sISLMhyEgsMyR8ym1GZfjO4jr14Yb1+cvOkn92v8rlm9jBqcbz64uV2VLrrt3fHd9Rei/Wkxz377+zTm6/rm7XQjKw1dPLEnT/+r1rstb126v8K1RljITZsmtwVXNdkE9vU6fOfLv/kUnV2EW+dv0lFOKrTRtu7pVp7GxTUvH9z+eEjo6uuv3XO6XU59XinfGjixcE+fNg/f718/f3b76FHQABqZOrzuM1W7f/QR0/svfnvZluQ7RllObvQSt7UaCEBh89fr+y/G5Y+t7FbHMzOdnVxC35aNc8sz/PnDC+b+tl1fnG/nl5/p+aMwY5fA2G6Rg7NL/+Wy3P7zB27wvPgqxpvTGoxyKVzj0uYXp6+/08+y3Lzy91/Frr1c/RXhm7QOJdeTjx+dffLVuxFKT5Ev84/lnSSmn8mZCvMtAeAy7EwjAZFZq2uc91Oa5zKajng/Xl+8uPlyetw8fTdNK4xB2g+69eb2Z3/9v/7qC/vkM7Enl8Y4D8ur6e8f/+P/mWdoKc35zlCyD0rk/G5iZO/KcVWyYtkL3UbGRzKJ//QxLs/ciX5y9tm/+P5MK3Vj8LrdfD4dir1eXfz8288evqrpNDw/fvnmlf3R5sP29OqhLqXObF3efKbrakjyAeaUwx6GknIazx6IRg133/rbh09Nf7r+m/2Fv60n3o1Oskb20XNJr+zLvGnL4XydT6Hn9764obR/bvqZr42z7s3Tn3BkV7Q6renYFV3epFV81PvSudWPHh4P71uPah98+Wdrd2O3uRR0k1tZyfv2Ikr4lOLyKii+9+F8amxk5LeucOxpTfbB//5OvLcVXB3dEYNmvusf+y3FVC36spz/9JwMrY9gL55t1ox36pd6YctWeYqnp+tbfFoMC706tGclTvlFfrD9pXLz8Hy32Eep/PZ/8gyjquv5/qyuV5HRF2gXZ8wPH75oNw4dDveGo/fe1TSW42RdDGcJLrKa6WxeHoAdf/NH912+Dd9Kj/W1iaexe852/fTDf/R/LaRsPFXqukEbMpMRKTY0z87evPrGuhl7Gbn6NIcOHbfzzcG2KUSq85RzxFZbczbpm6YB9ytPvjCbr784n/3PPkY7P3r57J/e86zC2B9iNsiZfMJCzr68P375bruaLI0IsHnZcXOkaN3juwn6egRIsBjno2HP53+E/5p580Gt/fz2kALcvyaa0ne/CN+aZ0S/apIFRjCsysbv9j/56Ord09OEZAZx4fTq2y89Wqlme7kZh6VyKjIe9xUaR+Z1mNxtu91o9+KoZnB9SYk64Q++/OR8f3DRQp9EQJQyaIXrH46rrdsKmxI0K4XePOuDxyUZ9/DUHG6HYV+VxB3nyPNNzz++uTzn5Mp8NT3z8SCRip+Xi+YjJ399q9qSzKWy5Fz1+OfjB2xPbHEJ7piYlqefgnjM5IdaHzy63BnrK9kw2P2hTl18cPppuMjF+zv5sSa+gS29aN3iu7dX1235fA89WE5lylRf3IcPGjiLNkh1wB4Uw5F/YZYplCIyUTjdnW68oKa9OXgN03ube6QJMs37m4o8tZf009McDNndr168fHN1R/22MdamL15O8zvL1eXag4XqK9dY8zHKj9aTo7Go8lEHAGuNKUyHeFXLVX+FDo53OrhLNX0uFxv7BotYp2Auzsvd/s2MkpVHWT75Z3er07JK6z3Y9cEmyun+Hup1cotZAErMiDV7V4BNmRdd5t0vumYpRMMbbkLcNw821t7bRa0AL709H/Y397cz35UyGFy123tnczMHH63G4UpXH7/1R9/7KVpbrJlNQUrVItBohySjc28eYJ5j82f0vBW6O704s+fHnbra1CLepMOcy5IOB673X2to410lEuVXQqqlXK6vXz/+n7/2WeOzagF73MY5FQo5SDb89BMbmJ0vz58cDda8DltqrFegpJXn6U3dH8blZpiXRSwgxjXS2/d5vL++TS493vW/1QzLR+8Mi1R1FX1prBFeFpilqSefn3k77dhvCojYqe8+su/kgIVMUVgo5/vjcD0WqbX5Yponv5Uu33JJ1coMF8Ddt/+0yfzrn5bSWLOA1nYkKJrqip98Hk9GBxVDP1prcu3Nj+z2upqpn0VZYUoHc5czM7tQ/vTy4LTuX49p0dzmA/gyDu/9+OUl/Mlvpc/SylcvORACVGn6t/5yeILJh7Iq670xovPTTz61TYVsZxCGzOWod3miWoO3Yc/rH/zjNJbDVfUOUhnvbgY9sA4SfvD2N4770U5t1UXJrLu3+p8tOzp2gaVFz1ZXI1x+/9zWRFJj5YIMS+FlwgI9eQfNOwRvTuu8P+YuOwT86L6uPjn4Mnl6/vLxwxaXUoLFxnq7/7C01Q1N6dhxiS2ff3Z+/9JbxSx4DMDWzlh4L0zWYrvtuq7KuvtYF0NjNsGUT8u6XEnMkl3HL1/4izNqMMpynHHxhhvusVhyr292w4PTH//+M/ZWKSEygRUDmY+LkvV2d3px3JWlgZs87+8varb2/nWUe1fWaHmupAHKm7GdzysXg4MXZ9r7NYjE5S9gbL7607D62JH9999eC2kijEvKabAS227XPXRWqg9Dnq/24ydbiq8P4jJVUiUplCgHl0yE2VvlkBDJssvNrNsfvmr8u8ePfzM/C2p//uAtt5DFnLnoEmDlW3d2oa7O2ac0peNsaNreTxgqutLHWS1L9aJF6tGXGq1aJ9YYJK1M+8Plzbfkb84ff1haInzjoAIuMpWS9Nw9vlw9Pg/iPJmZ9of9ZNFsjjdAji32D55GIYRaa17qUmUGMVycJ4vKZglVH//W1x//rD/b/CQC23ag2ZVkOF4Vt3VvnY3aOKvhJtpDmg9ZIWiYrQBE120u4/S5GKZCBQiLbTHD9j4K+1SVmsW67e79H/gHT385tQCW7xHj3cqYbKBfzLpaS5jlCJhLhJTAAjljxMTVg5UJ9VSuEwggQkHOEfzieqgm4T5m5m6h2+3NBycP/3ODymSWhaBRFaidehdZeLz98j6RmVsuhr048miMay8vN2CrXJw6C4osSlWZxVULtODCI7H7vA2jf3f11i+OQIKkRRgoY50aD7avpRzTiwkP88I+GQiVwItjG7o1oMsV6fTEWQEUUANcGeus0I6lsjrzcadd/s7D+P2IbIGoHHyWkGXnKrhmrIf0WcrpuH9zuLvnCh4EOIE2K6OT5VMoTb92rgKwWQrISEXnohZryP2QsvNzPPkfM1pksliPJwWFI3IDNs3lOC5nksYjlpLtgu1gdaxWQ6sjelkcJ+xKNUUNGF22x5z80h077py4L+J9Qw7+34fWMIJYdV+emQSrVIwVHZd6vMGhv4GmQjXGCJiqICYCp0yIh7y+BdOlhYTT2tbEWZnRCArE+Wb94rvX/d/+uSMhALK4efWd2ahiBVdoyK+PpY4vi3WindbQEGQksaxTBymJqa0qaV8Keq4eGFKNzhcza3rwk64p1+GLHxICsMVqWb9AW8ISEy7+6u7uMI3sAhTVXLbX5k7VCLiqe67VSTLuAGYyHFKXoWTwlP3Ski00n9mPulM7PPsLgyBgqiVr6zFVmz0nh7e3x2Me9a2v15Sv5Sbdoqm1GtHZWb1fyG6yQuqwOus9WgVxSzt7bkRAd6vPankeP5mMYURRBLWKKduqOnrUm1J5grd/bzcPy9myPVxlOzWZ2WVNU1eofQ3iRopo1a0ohWT8osQNIKNvw4cdlITiABEQSNAqwryZ/RCL2eNSJ7P6duB0fmw59qcvuEW3GEZbZRI7+kiFFhGPnbVEANxwDgHEEsTbuw4UgURIVR0TW1RlR8xUapqz5rPLC3PT1ehuTt1wlCEGs+ReDOHMZsmNZz9668UGOGwTGA7RVGtrQx9ak40REMsIKKai3ViTQMFVzePMxzP7gJKfJYTTozS7fXBEGh2bwrYq02RwaroQswC14AQteYiLc5TyA8OCwkyQBXJEsP8G5tsJq82pzMsEF+OWi9R5p4RtWedznTywd2stcZ90zkNnPIp0BxPB+BFdjcaYak1+0LvWmQa0C3h9s797I7b69jgjm6ku05Iv43pbktmzWHOAyfizFEripvdGrJ/SSXqTjBqG0t50xrQHo42xBdrql5aoutA23vcmLM03/WhvV1173aouNh35vLnYAdeJy+1qmcc65wAUsK+hSS6xAMXdFYuYqqKzmU3w0oJiDuX05PnsXIg2GEfWTUN9+MTau9qrQrU6cBtOztdDhUqcYxoPR4OlaDRHggXSsqCbfT9Gt3UjqTOJqtUgBBIXOM1rZ5teSrUefRSgJdtOJ0cZiyni4+rpbuZUtZamSjmCS1WLkmgQxQWN2mY6R1OREimzWbyThpmkbgbpV+Daw76eGwOrmKMXaxvQkHMjZWrad2JmMffWbPA4STunlF2mVCUXy9FFachZk2BRYjME9QZjuCep8DhzVFdhSm4WR+E8e2/JOuvPFqphCXHTypBo7psuYBKHtdS/q9YMsOq3bhUMWaWCBbJ6BIPYs1jBzbkgotbb0TBUJHPaG98QhegeOmK0kVsaq/iGemWK7SZ0Vp2KMAlT16/IOWON9ZZLqQvaYg02MHl2y5O3csCapyO5YIGM2UXvs0WDJe6uwGgy3aHaTaktzL0FO+66W2WkIEZiaHpTrNjqDU0gbERVSZFIQBw+8p1iXgCQ0Cha8GuHSga9XP1uX4sZN8roJDMufeNoZU9X7Ul7dr7brk5XfUfkw9pCXrw1VTlkQQmm5aYYefCorJdS0UaoNcjSUNuTjZZQ6Xb3B/+h+tCIdrXMPpNTgZkybXUlmIrhmC2hh0RRC9tSK/scDIhHxraUb2r2SwEjFI6oDbp43N2jJa9Wquv/sLEbyghLtWAolURzzZmN6WCzbjrXB4hWHKgNk+NatTSiTrqimbh9nBZZCKpNaJ3QqjrszkRJLFm23P7LJjSKLATWHMeDACcGh8CYUa1pG9cIzpBrXUQUFah2GISVtPwGJYifW1gA8aTZetxnsr41hEqhE4T0r9xszNjO85ixRqx1YTQYwVhtvfHIBVo6UpI6VBOmip0gKZHyo6c529NfjBoW65vHPiCxmVQmYjRDr8qMf1hTCnWSeZFQUx0XlSzzmERL0qSh8sCQNNcBKBg3ERlXkXH8nZq9Q/O6usZa31olWkwECcRCeCICMn7lH/KtT1khJxIYRp6HZVrKVDVzyqI5zermepxzXkxQVlIClfHrfRbjrh+8yUjBOBtQsdp1JbFi6nJSlBXGb9o/vo4w6gx3Fo4CaVrREc1Bowk4iV0MjLRkyJhGNAnHNYEY9yu1eDW3tiBUbxySAtZYkhqLZUmxJhWg/C7+YAkj1lSJUsaUPLOpys4uJHMo1WVBRmQZuXGLMRWhvm+r2lSxXzB5sBrAsyU5iCFrE+1tzSIIWL/yB//F+XEZRe1UBdKMBTzhCCDAY1UuDH6RaopJJlMYVunykahVntarhS1SNWqUFFJC8MSqSIygUkpeNt9bkEJd5omzGD/VSY5TnebhOBdGnIyDYZxTEtFc22Sn7jEpmqrD6qxZWgJkVkXmktA0hJobJmMDWeE6x38SnVWomYNWhEHqMpcyTvPIfEThMldxTFDAWBxc89AhOa2M6fzh0UTFKgU41wGw8WRwsRmB0JMxItn/3jf8pglYC6FlQlFceFlqnpVY5jGpJ3I+eJ4GovNGCFGAa12vAUEAa+Fa5gSxaSwI2/vLpGLIiTKLfv3kL4/3QxatukrZuupqBSTIcscCbBUMAM/UeTqNQmRYklSPZy+mlRKpFJkFYrRqlaD79O2RQcAICRTW3T949eXPgNUkbNjZjCYRcmYohrkRQoS8nZoz88CV1hNWFmZW99WPTyYgyVWKeO9I/z/dS76RGCES3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PpmImagePlugin.PpmImageFile image mode=L size=92x112>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = next(paths)\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(file)\n",
    "print(f\"Shape: {np.array(img).shape}\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are shaped (112, 92, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 112, 92, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "X = rng.random((32,) + np.array(img).shape + (1,))\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the siamese model is to have an encoder that transforms images into vectors.\n",
    "Our basemodel is a basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Conv                (32, 112, 92, 1)   (float64) | (32, 37, 30, 96)   (float32)\n",
      "(1) Relu                (32, 37, 30, 96)   (float32) | (32, 37, 30, 96)   (float32)\n",
      "(2) Conv                (32, 37, 30, 96)   (float32) | (32, 18, 14, 256)  (float32)\n",
      "(3) Relu                (32, 18, 14, 256)  (float32) | (32, 18, 14, 256)  (float32)\n",
      "(4) Conv                (32, 18, 14, 256)  (float32) | (32, 8, 6, 384)    (float32)\n",
      "(5) Relu                (32, 8, 6, 384)    (float32) | (32, 8, 6, 384)    (float32)\n",
      "(6) Avg2D               (32, 8, 6, 384)    (float32) | (32, 384)          (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 384), dtype:float32}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Avg2D():\n",
    "    return tl.Fn(\"Avg2D\", lambda x: x.mean(axis=(1, 2)), n_out=1)\n",
    "\n",
    "\n",
    "@assert_shape(\"bwhc->bd\")\n",
    "def Encoder(config) -> cb.Serial:\n",
    "    model = cb.Serial(\n",
    "        tl.Conv(config[\"filters1\"], kernel_size=(3, 3), strides=(3, 3)),\n",
    "        tl.Relu(),\n",
    "        tl.Conv(config[\"filters2\"], kernel_size=(3, 3), strides=(2, 2)),\n",
    "        tl.Relu(),\n",
    "        tl.Conv(config[\"filters3\"], kernel_size=(3, 3), strides=(2, 2)),\n",
    "        tl.Relu(),\n",
    "        Avg2D(),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"filters1\": 96,\n",
    "    \"filters2\": 256,\n",
    "    \"filters3\": 384,\n",
    "}\n",
    "encoder = Encoder(config)\n",
    "encoder.init_weights_and_state(signature(X))\n",
    "summary(encoder, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can check, we start out with a batch of 32 images, each (112,92) big, with 1 channel.\n",
    "Our model has three layers, and transforms the images into vectors of lenght 384.\n",
    "\n",
    "The idea of the siamese model is to calculate the distance between the two.\n",
    "We will subtract and calculate the L2 norm, $$\\sqrt{||x_1 - x_2||^2}$$\n",
    "\n",
    "This is a generalized form of the Pythagoras formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07719866, 1.14299861, 1.02750944, 0.65954882, 0.98387584,\n",
       "       1.02697084, 1.07833309, 0.99599219, 0.82441366, 1.1453552 ,\n",
       "       1.46424912, 1.21094332, 1.54924209, 1.24016068, 0.72707926,\n",
       "       1.16887726, 1.01208151, 1.17729566, 0.96513907, 0.92295388,\n",
       "       1.12956337, 1.36923379, 1.07489065, 0.9027057 , 1.11131096,\n",
       "       1.30398411, 0.7336572 , 1.26711052, 1.27269505, 0.96871354,\n",
       "       1.04435153, 0.88830364])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = rng.random((32, 8))\n",
    "x2 = rng.random((32, 8))\n",
    "yhat = rng.integers(0, 2, 32)\n",
    "distance = np.linalg.norm(x1 - x2, axis=-1)\n",
    "distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim is:\n",
    "we want the images from the same class (the same person) to be close to each other, and images from different persons to be far away.\n",
    "\n",
    "We do this with contrastive loss:\n",
    "$$\\hat{y} * d + (1-\\hat{y}) * max(0, m - d)$$\n",
    "\n",
    "where $m$ is the margin we choose as \"close\".\n",
    "Let's implement this as a proper loss class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.6684706, dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ContrastiveLoss:\n",
    "    def __init__(self, margin: float = 1.0):\n",
    "        self.margin = margin\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"ContrastiveLoss\"\n",
    "\n",
    "    def __call__(self, y1, y2, yhat):\n",
    "        distance = jnp.linalg.norm(y1 - y2, axis=-1)\n",
    "        distance_ = jnp.clip(distance, 1e-14, 10)\n",
    "        return jnp.mean(\n",
    "            yhat * distance + (1 - yhat) * jnp.maximum(0, self.margin - distance)\n",
    "        )\n",
    "\n",
    "\n",
    "loss = ContrastiveLoss()\n",
    "loss(x1, x2, yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With trax, creating a Siamese network is a piece of cake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siamese(config):\n",
    "    encoder = Encoder(config)\n",
    "    model = cb.Parallel(encoder, encoder)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapeDtype{shape:(32, 384), dtype:float32},\n",
       " ShapeDtype{shape:(32, 384), dtype:float32})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = rng.random((32,) + np.array(img).shape + (1,))\n",
    "img2 = rng.random((32,) + np.array(img).shape + (1,))\n",
    "y = rng.random(32)\n",
    "siamese = Siamese(config)\n",
    "siamese.init_weights_and_state(signature((img1, img2)))\n",
    "x1, x2 = siamese((img1, img2))\n",
    "signature((x1, x2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.4690957, dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x1, x2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is left to do is to create a proper dataloader, and to wrap everything in a trainloop.\n",
    "\n",
    "Another strategy would be to use transfer learing;\n",
    "e.g. if we load a pretrained resnet from torchvision, and slap on a final Dense layer, \n",
    "our training is probably faster and more accurate."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
