{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools, make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 18:47:16.216 | INFO     | src.data.make_dataset:get_flowers:62 - Data is downloaded to ../../data/raw/datasets/flower_photos.\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../../data/raw\")\n",
    "image_folder = make_dataset.get_flowers(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data_tools.Dataloader(path=image_folder, split=0.8)\n",
    "train_datastream = dataloader.data_generator(\n",
    "    batch_size=32,\n",
    "    image_size=(150, 150),\n",
    "    channels=3,\n",
    "    shuffle=True,\n",
    "    mode=\"train\"\n",
    ")\n",
    "test_datastream = dataloader.data_generator(\n",
    "    batch_size=32,\n",
    "    image_size=(150, 150),\n",
    "    channels=3,\n",
    "    shuffle=True,\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 150, 150, 3), (32,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(train_datastream)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 150, 150])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.from_numpy(X).float().permute(0, 3, 1, 2)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 38, 38])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "relu = nn.ReLU()\n",
    "maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) \n",
    "\n",
    "x = conv1(input)\n",
    "x = relu(x)\n",
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 128, 19, 19]), torch.Size([32, 128, 19, 19]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = 64\n",
    "out_channels = 128\n",
    "stride = 2\n",
    "conv3x3 = nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "conv1x1 = nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        padding=0,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "x2 = conv3x3(x)\n",
    "identity = conv1x1(x)\n",
    "x2.shape, identity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels: int, out_channels: int, stride: int=1) -> nn.Conv2d:\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "def conv1x1(in_channels: int, out_channels: int, stride: int=2) -> nn.Conv2d:\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        padding=0,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(in_channels, out_channels),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "            stride = 2\n",
    "        else:\n",
    "            self.downsample = None\n",
    "            stride = 1\n",
    "\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 38, 38])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 38, 38])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicblock = BasicBlock(64, 64)\n",
    "x1 = basicblock(x)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 19, 19])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicblock = BasicBlock(64, 128)\n",
    "x2 = basicblock(x1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n",
      "64 64\n",
      "64 128\n",
      "128 128\n",
      "128 128\n",
      "128 256\n",
      "256 256\n",
      "256 512\n"
     ]
    }
   ],
   "source": [
    "layers = [64, 64, 64, 128, 128, 128, 256, 256, 512]\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    print(layers[i], layers[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes, layers) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) \n",
    "        block_num = len(layers) - 1\n",
    "\n",
    "        self.blocks = nn.ModuleList([BasicBlock(layers[i], layers[i+1]) for i in range(block_num)])\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flat(x)\n",
    "        out = self.fc(x)\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(dataloader.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet(num_classes=num_classes, layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6753733"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = resnet(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rgrouls/code/deep_learning/notebooks/2_convolutions/06_resnet.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rgrouls/code/deep_learning/notebooks/2_convolutions/06_resnet.ipynb#ch0000021?line=0'>1</a>\u001b[0m test_datastream\u001b[39m.\u001b[39;49mdataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "test_datastream.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rgrouls/code/deep_learning/notebooks/2_convolutions/06_resnet.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rgrouls/code/deep_learning/notebooks/2_convolutions/06_resnet.ipynb#ch0000022?line=0'>1</a>\u001b[0m test_datastream\u001b[39m.\u001b[39;49mbatch_size\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "test_datastream.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import train_model\n",
    "\n",
    "train_model.trainloop(\n",
    "    epochs=10,\n",
    "    model=resnet,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    train_dataloader=train_datastream,\n",
    "    test_dataloader=test_datastream,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26ecd70c250b5fc210d88fc9e1a14b5d0dd9aee31ae2ed2f5669e6e14392ba9e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep-learning-xB8KIJr7-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
