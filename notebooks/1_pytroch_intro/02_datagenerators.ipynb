{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Design pattern for data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical setup for machine learning is that we have an amount of observations, with multiple dimensions. Lets say we have images, size (28, 28) pixels and three colors, so (3, 28, 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = (50, )\n",
    "datasize = (3, 28, 28)\n",
    "\n",
    "dim = observations + datasize\n",
    "\n",
    "X = torch.rand(dim)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid clusters of observations that are highly correlated, we would want to shuffle the data. While we could shuffle the data itself, it is better to use an index and shuffle the index.\n",
    "\n",
    "This approach is especially useful if your data is too big to fit into your memory. Also take into account the model that runs transformations on your data: it will take up a multitude of the original image.\n",
    "\n",
    "In that case you would want to feed the model a list of paths to images, files etc, and load a batch of images while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27,  7, 45, 41,  8, 17, 48, 28, 39, 37, 16, 30, 25, 32,  1, 12, 10, 22,\n",
       "        29, 36, 26, 46,  4, 11,  6, 38, 23, 21,  0, 24, 20, 43,  2, 35, 49, 19,\n",
       "        15,  3, 34, 14,  5, 47,  9, 33, 13, 18, 44, 42, 31, 40])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = torch.randperm(len(X))\n",
    "index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `torch.randperm(n)` we obtain a random permutation of the numbers from 0 to $n$. Next step is using a generator. Simple generators are introduced with [PEP 255](https://www.python.org/dev/peps/pep-0255/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7f411fc8ec80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = (i for i in range(10))\n",
    "gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `next` on a generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a second time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is usefull if we want to generator lists that are infinite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib():\n",
    "    a, b = 0, 1\n",
    "    while True:\n",
    "       yield b\n",
    "       a, b = b, a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n",
      "34\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "fibonacci = fib()\n",
    "for i in range(10):\n",
    "    print(next(fibonacci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the generator pattern to yield a dataset in batches of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_generator(data, batchsize):\n",
    "    index_list = torch.randperm(len(data))\n",
    "    i = 0\n",
    "    while True:\n",
    "        index = index_list[i:i+batchsize]\n",
    "        X = data[index]\n",
    "        yield X\n",
    "        i += batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will scramble an index, and take a batch-sized chunck of these indices to yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([32, 3, 28, 28])\n",
      "Shape: torch.Size([18, 3, 28, 28])\n",
      "Shape: torch.Size([0, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "gen = naive_generator(X, 32)\n",
    "for i in range(3):\n",
    "    batch = next(gen)\n",
    "    print(f\"Shape: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we run into a problem: after two batches, we ran out of data and we will yield empty tensors...\n",
    "\n",
    "To solve this problem we will use a nested index:\n",
    "- `i` loops over the batchsize\n",
    "- `index` loops through the `index_list`\n",
    "- every time the `index` would go beyond the datasize, we reset it, and shuffle the `index_list`\n",
    "- The data is collected in a tensor `X` with the nested `index_list[index]` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, batchsize):\n",
    "    size = len(data)\n",
    "    shape = data.shape[1:]\n",
    "    index_list = torch.randperm(size)\n",
    "    index = 0\n",
    "\n",
    "    X = torch.zeros((batchsize, ) + shape)\n",
    "    while True:\n",
    "\n",
    "        for i in range(batchsize):\n",
    "            # i will always run from 0 to batchsize,\n",
    "            # regardless of how many items you have left\n",
    "            if index >= size:\n",
    "                # if your index goes beyond the amount of data\n",
    "                index = 0\n",
    "                # we reset it to zero\n",
    "                index_list = torch.randperm(size)\n",
    "                # and shuffle the index_list\n",
    "            \n",
    "            # we use the index (that goes from 0 to size)\n",
    "            # to grab the next (shuffled) index_list item\n",
    "            # and fill batch i with it\n",
    "            X[i] = data[index_list[index]]\n",
    "            index += 1\n",
    "        yield X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([32, 3, 28, 28])\n",
      "Shape: torch.Size([32, 3, 28, 28])\n",
      "Shape: torch.Size([32, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "gen = generator(X, 32)\n",
    "for i in range(3):\n",
    "    batch = next(gen)\n",
    "    print(f\"Shape: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we have only 50 observations, we dont run out of data. We will keep shuffling the data an can generate infinite batches, shuffled every time."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f991136b32d0e931878e2d826f60fb70ad3d0a23fd6e1a56ea114087d779837"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep-learning-uo9RXddf-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
