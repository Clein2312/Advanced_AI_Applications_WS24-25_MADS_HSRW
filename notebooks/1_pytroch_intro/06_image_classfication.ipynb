{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow for a data science project will follow these lines:\n",
    "\n",
    "1. Get and explore the data\n",
    "2. Build a model \n",
    "3. Train the model\n",
    "4. Save and predict\n",
    "\n",
    "## 1. Get and Explore the Data\n",
    "The first step can take quite some time; data quality is often something that needs to be checked, and correlations between data should often be explored and visualized.\n",
    "\n",
    "This step can be a full project on its own: you clean the data, make sure you can access it properly, and create visualizations and hypothesis to gain insight into the data that can be shown in a dashboard.\n",
    "\n",
    "The insight in the data is an essential ingredient for deciding on a model.\n",
    "\n",
    "## 2. Build a model\n",
    "Based on domain knowledge and a first exploration of the data, a model can be selected.\n",
    "\n",
    "Sometimes, the relation between features and outcome is very obvious. You might have features that\n",
    "correlate very high with the outcome variable, and a domain expert confirms that the correlations make sense.\n",
    "\n",
    "If this is the case, you can often build a simple model. If you expect to have non-linear and complex interactions between the features,\n",
    "you could use a model that works with non-linear data like a SVM plus kernel, or a random forest.\n",
    "\n",
    "If you have enough data (as a rule of thumb, a lower threshold of 1000 observations) you can consider a neural network architecture.\n",
    "If the expected complexity of the data is low, you can use a relative small network.\n",
    "If you have lots and lots of data with a high complexity, you should consider to increase the complexity of your model too.\n",
    "\n",
    "How you can build a model, and what suitable models are for different datatypes and situations, will be the subject of the whole course.\n",
    "\n",
    "## 3. Train the model\n",
    "Once you created a model, it hasnt learned anything yet. The model must be trained to learn the right connections, a bit like a baby that has to learn about what works and what doesn't.\n",
    "\n",
    "In this notebook, I will introduce you to PyTorch. Another high level library is Tensorflow, which is used a lot too.\n",
    "While the interface is comparable, the Tensorflow syntax is a bit more high-level. While this can be an advantage, \n",
    "it also has a downside: at the moment you ever need to dive a bit deeper into the architecture itself, it is much harder to\n",
    "add something new with TensorFlow, compared to PyTorch.\n",
    "\n",
    "## 4. Save and predict\n",
    "Finally, you will want to use the trained model to predict new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "We will use the fashion MNIST dataset. You will find this dataset a lot in machine learning tutorials. It are small (28x28) images of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../..\")\n",
    "from src.models import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "\n",
    "from pathlib import Path\n",
    "datadir = \"../../data/raw/\"\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=datadir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=datadir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have `torch.datasets`. They implement at minimum an `.__getitem__` and `.__len__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data, we can use the __getitem__ method by calling an index, just like you would do with a list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Tensor, int)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = training_data[0]\n",
    "type(x), type(x[0]), type(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = training_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a tuple. We can check the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the 0th item, which is the image (tensor). The other item is the label (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the image has a channel-first convention: it is a 28x28 pixel image, and it has 1 channel (grey). Look into the official documentation if you want to know more about datasets and how to build your own: [docs](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Ok, we want to batch this into a dataloader. From the documentation:\n",
    "\n",
    "> The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the length of the dataloader different from the dataset? We had 60000 items before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we see here? Our datashape has four dimensions:\n",
    "\n",
    "- 64: this is the batch size. Every batch has 64 observations; in this case 64 images\n",
    "- 1: this is the channel. Colorimages typically have 3 channels. Our images have just one color, and thus 1 channel. So images can have more channels (e.g. infrared etc)\n",
    "- (28,28) : this is the actual image, with dimensions 28x28\n",
    "\n",
    "Lets visualize the first example, the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16d581610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you recognize the setup from the `linearmodel` notebook. \n",
    "\n",
    "- We will `Flatten` the image. That means we will transform our (64, 1, 28, 28) data into (64, 784) shaped data. What we do here, is flattening the image into a one dimensional vector.\n",
    "- We have a stack of hidden layers. These are essentially dotproducts. Our vector of 784 (28*28) elements is transformed into 512 elements, and then into 10 elements because we have 10 classes.\n",
    "- in between the linear transformations you can see the activation functions,here a `ReLu` \n",
    "- The `forward` method is what is called during training. This gives you control over the flow of information: it is easy to create some parallel flow of data if you want to do something like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an optimizer. We will dive into this in later lessons.\n",
    "\n",
    "For now, it is enough to know this:\n",
    "\n",
    "Your model makes a prediction. But how does the model know if it is right, or wrong?\n",
    "And, more specific: how does the model know which weights it needs to modify in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 60000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"../../models/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 18:39:53.195 | INFO     | src.models.train_model:trainloop:69 - Epoch 0 train 0.0078 | test 0.0064\n",
      "2022-04-25 18:40:05.789 | INFO     | src.models.train_model:trainloop:69 - Epoch 1 train 0.0055 | test 0.0061\n",
      "2022-04-25 18:40:17.964 | INFO     | src.models.train_model:trainloop:69 - Epoch 2 train 0.0049 | test 0.0059\n",
      "2022-04-25 18:40:29.796 | INFO     | src.models.train_model:trainloop:69 - Epoch 3 train 0.0046 | test 0.0051\n",
      "2022-04-25 18:40:42.146 | INFO     | src.models.train_model:trainloop:69 - Epoch 4 train 0.0043 | test 0.0052\n",
      "2022-04-25 18:40:54.028 | INFO     | src.models.train_model:trainloop:69 - Epoch 5 train 0.0040 | test 0.0054\n",
      "2022-04-25 18:41:05.678 | INFO     | src.models.train_model:trainloop:69 - Epoch 6 train 0.0039 | test 0.0053\n",
      "2022-04-25 18:41:17.612 | INFO     | src.models.train_model:trainloop:69 - Epoch 7 train 0.0036 | test 0.0059\n",
      "2022-04-25 18:41:29.907 | INFO     | src.models.train_model:trainloop:69 - Epoch 8 train 0.0036 | test 0.0053\n",
      "2022-04-25 18:41:43.961 | INFO     | src.models.train_model:trainloop:69 - Epoch 9 train 0.0033 | test 0.0053\n"
     ]
    }
   ],
   "source": [
    "model = train_model.trainloop(\n",
    "    epochs=5,\n",
    "    model=model,\n",
    "    optimizer=optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    log_dir=log_dir,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    eval_steps=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = Path(\"../../models\") \n",
    "model_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = model_dir / \"trained_model\"\n",
    "torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch $X$, $y$ and make a prediction $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(test_dataloader))\n",
    "yhat = loaded_model(X)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy:\n",
    "- for every example we have 10 numbers\n",
    "- the location with the highest value is the prediction\n",
    "- we can get the index with `argmax` over dimension 1\n",
    "- we compare that index with the original number\n",
    "- This gives us a count of all the correct predictions\n",
    "- dividing that through the total length gives us the accuracy percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.1875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (yhat.argmax(dim=1) == y).sum() / len(y)\n",
    "accuracy.item() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the accuracy for a single batch! \n",
    "Get another batch by running next() in the cell above, and calculate the accuracy again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 18:44:37.145 | INFO     | src.data.data_tools:clean_dir:121 - Clean out {dir}\n"
     ]
    }
   ],
   "source": [
    "cleanup = True\n",
    "from src.data import data_tools\n",
    "# to remove the trained model\n",
    "if cleanup:\n",
    "    modelpath.unlink()\n",
    "    data_tools.clean_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f991136b32d0e931878e2d826f60fb70ad3d0a23fd6e1a56ea114087d779837"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep-learning-uo9RXddf-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
