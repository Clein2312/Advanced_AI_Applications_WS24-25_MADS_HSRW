{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow for a data science project will follow these lines:\n",
    "\n",
    "1. Get and explore the data\n",
    "2. Build a model \n",
    "3. Train the model\n",
    "4. Save and predict\n",
    "\n",
    "## 1. Get and Explore the Data\n",
    "The first step can take quite some time; data quality is often something that needs to be checked, and correlations between data should often be explored and visualized.\n",
    "\n",
    "This step can be a full project on its own: you clean the data, make sure you can access it properly, and create visualizations and hypothesis to gain insight into the data that can be shown in a dashboard.\n",
    "\n",
    "The insight in the data is an essential ingredient for deciding on a model.\n",
    "\n",
    "## 2. Build a model\n",
    "Based on domain knowledge and a first exploration of the data, a model can be selected.\n",
    "\n",
    "Sometimes, the relation between features and outcome is very obvious. You might have features that\n",
    "correlate very high with the outcome variable, and a domain expert confirms that the correlations make sense.\n",
    "\n",
    "If this is the case, you can often build a simple model. If you expect to have non-linear and complex interactions between the features,\n",
    "you could use a model that works with non-linear data like a SVM plus kernel, or a random forest.\n",
    "\n",
    "If you have enough data (as a rule of thumb, a lower threshold of 1000 observations) you can consider a neural network architecture.\n",
    "If the expected complexity of the data is low, you can use a relative small network.\n",
    "If you have lots and lots of data with a high complexity, you should consider to increase the complexity of your model too.\n",
    "\n",
    "How you can build a model, and what suitable models are for different datatypes and situations, will be the subject of the whole course.\n",
    "\n",
    "## 3. Train the model\n",
    "Once you created a model, it hasnt learned anything yet. The model must be trained to learn the right connections, a bit like a baby that has to learn about what works and what doesn't.\n",
    "\n",
    "In this notebook, I will introduce you to PyTorch. Another high level library is Tensorflow, which is used a lot too.\n",
    "While the interface is comparable, the Tensorflow syntax is a bit more high-level. While this can be an advantage, \n",
    "it also has a downside: at the moment you ever need to dive a bit deeper into the architecture itself, it is much harder to\n",
    "add something new with TensorFlow, compared to PyTorch.\n",
    "\n",
    "## 4. Save and predict\n",
    "Finally, you will want to use the trained model to predict new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "We will use the fashion MNIST dataset. You will find this dataset a lot in machine learning tutorials. It are small (28x28) images of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 20:26:44.029719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-25 20:26:44.029755: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.models import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "\n",
    "from pathlib import Path\n",
    "datadir = \"../../data/raw/\"\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=datadir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=datadir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have `torch.datasets`. They implement at minimum an `.__getitem__` and `.__len__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data, we can use the __getitem__ method by calling an index, just like you would do with a list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Tensor, int)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = training_data[0]\n",
    "type(x), type(x[0]), type(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = training_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a tuple. We can check the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the 0th item, which is the image (tensor). The other item is the label (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the image has a channel-first convention: it is a 28x28 pixel image, and it has 1 channel (grey). Look into the official documentation if you want to know more about datasets and how to build your own: [docs](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Ok, we want to batch this into a dataloader. From the documentation:\n",
    "\n",
    "> The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the length of the dataloader different from the dataset? We had 60000 items before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we see here? Our datashape has four dimensions:\n",
    "\n",
    "- 64: this is the batch size. Every batch has 64 observations; in this case 64 images\n",
    "- 1: this is the channel. Colorimages typically have 3 channels. Our images have just one color, and thus 1 channel. So images can have more channels (e.g. infrared etc)\n",
    "- (28,28) : this is the actual image, with dimensions 28x28\n",
    "\n",
    "Lets visualize the first example, the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5c491eeac0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you recognize the setup from the `linearmodel` notebook. \n",
    "\n",
    "- We will `Flatten` the image. That means we will transform our (64, 1, 28, 28) data into (64, 784) shaped data. What we do here, is flattening the image into a one dimensional vector.\n",
    "- We have a stack of hidden layers. These are essentially dotproducts. Our vector of 784 (28*28) elements is transformed into 512 elements, and then into 10 elements because we have 10 classes.\n",
    "- in between the linear transformations you can see the activation functions,here a `ReLu` \n",
    "- The `forward` method is what is called during training. This gives you control over the flow of information: it is easy to create some parallel flow of data if you want to do something like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an optimizer. We will dive into this in later lessons.\n",
    "\n",
    "For now, it is enough to know this:\n",
    "\n",
    "Your model makes a prediction. But how does the model know if it is right, or wrong?\n",
    "And, more specific: how does the model know which weights it needs to modify in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 60000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"../../models/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model.trainloop(\n",
    "    epochs=5,\n",
    "    model=model,\n",
    "    optimizer=optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    log_dir=log_dir,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    eval_steps=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = Path(\"../../models\") \n",
    "model_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = model_dir / \"trained_model\"\n",
    "torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch $X$, $y$ and make a prediction $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(test_dataloader))\n",
    "yhat = loaded_model(X)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy:\n",
    "- for every example we have 10 numbers\n",
    "- the location with the highest value is the prediction\n",
    "- we can get the index with `argmax` over dimension 1\n",
    "- we compare that index with the original number\n",
    "- This gives us a count of all the correct predictions\n",
    "- dividing that through the total length gives us the accuracy percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.1875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (yhat.argmax(dim=1) == y).sum() / len(y)\n",
    "accuracy.item() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the accuracy for a single batch! \n",
    "Get another batch by running next() in the cell above, and calculate the accuracy again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 18:44:37.145 | INFO     | src.data.data_tools:clean_dir:121 - Clean out {dir}\n"
     ]
    }
   ],
   "source": [
    "cleanup = True\n",
    "from src.data import data_tools\n",
    "# to remove the trained model\n",
    "if cleanup:\n",
    "    modelpath.unlink()\n",
    "    data_tools.clean_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f991136b32d0e931878e2d826f60fb70ad3d0a23fd6e1a56ea114087d779837"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep-learning-uo9RXddf-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
