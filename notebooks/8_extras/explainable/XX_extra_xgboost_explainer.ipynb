{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making models is really cool, but in practice, in businesses people often also want to know why a certain prediction was made. Understanding why predictions are made is the field of Explainable AI. It can be as important, and in some cases, even more important as making the most accurate prediction. \n",
    "\n",
    "SHAP (SHapley Additive exPlainations) is a game theoretic approach to explain the output of any machine learning model to increase transparency and interpretability of machine learning models. Consider a coooperative game with the same number of players as the name of features. SHAP will disclose the individual contribution of each player (or feature) on the output of the model, for each example or observation.\n",
    "\n",
    "*Important: while SHAP shows the contribution or the importance of each feature on the prediction of the model, it does not evaluate the quality of the prediction itself.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP can thus be applied to all kinds of models. SHAP has different ways of working for different kinds of models, in this notebook we will first go through SHAP for tabular data. We will first make an XG Boost model, which is a tree model. We will use the breast_cancer dataset that has 30 variables and 1 target which is binary and shows whether the person has breast cancer or not. SHAP will help us understand which of these 30 variables made the largest difference in a single prediction. If we calculate the mean SHAP values over all these samples, we can say which of the variables are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show as pd DataFrame\n",
    "df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "df['target'] = pd.Series(dataset.target)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "X = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "y = pd.Series(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#define train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "#prepare data for xgboost\n",
    "d_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "d_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "\n",
    "#train model\n",
    "model = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)\n",
    "\n",
    "#predictions = model.predict(d_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a model! Now we can start using the SHAP values to analyze the model\n",
    "\n",
    "First we have to define the explainer, because XGBoost is a tree model, we will use TreeExplainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single prediction\n",
    "\n",
    "We can visualize a single prediction. \n",
    "\n",
    "For this we can use the force plot, which is a way to see the effect of each feature on the prediction, for a given observation. In this plot the positive SHAP values are displayed on the left side and the negative on the right side, as if competing against each other. The highlighted value is the prediction for that observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init javascript in order to display the visuals\n",
    "shap.initjs()\n",
    "\n",
    "#item \n",
    "observation = 1 #the observation we are checking\n",
    "print(y.iloc[observation])\n",
    "shap.force_plot(explainer.expected_value, shap_values[observation,:], X.iloc[observation,:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show all the predictions in one single plot by not slicing as done in the above example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values, X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart of mean importance\n",
    "\n",
    "This takes the average of the SHAP value magnitudes across the dataset and plots it as a simple bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Summary Plot\n",
    "\n",
    "Rather than use a typical feature importance bar chart, we use a density scatter plot of SHAP values for each feature to identify how much impact each feature has on the model output for individuals in the validation dataset. Features are sorted by the sum of the SHAP value magnitudes across all samples. It is interesting to note that the relationship feature has more total model impact than the captial gain feature, but for those samples where capital gain matters it has more impact than age. In other words, capital gain effects a few predictions by a large amount, while age effects all predictions by a smaller amount.\n",
    "\n",
    "Note that when the scatter points donâ€™t fit on a line they pile up to show density, and the color of each point represents the feature value of that individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's it for the tabular data. We can also use SHAP for images. See the next notebook for SHAP on image data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-HWw5In8R-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jan  3 2023, 11:48:49) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7a2a84109baef7a65d7544440e725c32db11ce0f81af637277710b295bf52f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
