{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import data_tools, make_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import tokenizer, train_model\n",
    "import torch\n",
    "from src.models import metrics\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 22:55:09.231 | INFO     | src.data.make_dataset:get_imdb_data:99 - ../../data/raw/aclImdb already exists, skipping download\n",
      "100%|██████████| 25000/25000 [00:02<00:00, 8357.62it/s]\n",
      "100%|██████████| 25000/25000 [00:03<00:00, 8040.09it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../data/raw\"\n",
    "trainpaths, testpaths = make_dataset.get_imdb_data(data_dir)\n",
    "traindataset = data_tools.TextDataset(paths=trainpaths)\n",
    "testdataset = data_tools.TextDataset(paths=testpaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 22:55:18.328 | INFO     | src.models.tokenizer:build_vocab:27 - Found 79808 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=10000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = tokenizer.Preprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "trainloader = DataLoader(\n",
    "    traindataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testdataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full dataset has 782 batches of 32 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup accuracy and loss_fn (this is a classification problem with two classes, 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "log_dir = Path(\"../../models/attention/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic config. We need to specify the vocabulary lenght for the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import rnn_models\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base NLP model is just a GRU, with an embedding as a first layer.\n",
    "Trainsteps are set to just 100 batches for speedup in the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 22:55:35.629 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/attention/20221219-2255\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.25it/s]\n",
      "2022-12-19 22:55:45.863 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6954 test 0.6912 metric ['0.5262']\n",
      "100%|██████████| 100/100 [00:09<00:00, 10.99it/s]\n",
      "2022-12-19 22:55:56.068 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.6910 test 0.6776 metric ['0.5725']\n",
      "100%|██████████| 100/100 [00:09<00:00, 11.06it/s]\n",
      "2022-12-19 22:56:06.139 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.6800 test 0.6701 metric ['0.5925']\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.93it/s]\n",
      "2022-12-19 22:56:15.440 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.6912 test 0.6896 metric ['0.5637']\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.83it/s]\n",
      "2022-12-19 22:56:24.813 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.6911 test 0.6901 metric ['0.5275']\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.95it/s]\n",
      "2022-12-19 22:56:34.110 | INFO     | src.models.train_model:trainloop:171 - Epoch 5 train 0.6896 test 0.6992 metric ['0.5312']\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.73it/s]\n",
      "2022-12-19 22:56:43.565 | INFO     | src.models.train_model:trainloop:171 - Epoch 6 train 0.6924 test 0.6913 metric ['0.5288']\n",
      "100%|██████████| 100/100 [00:08<00:00, 12.01it/s]\n",
      "2022-12-19 22:56:52.832 | INFO     | src.models.train_model:trainloop:171 - Epoch 7 train 0.6943 test 0.6897 metric ['0.5250']\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.98it/s]\n",
      "2022-12-19 22:57:02.144 | INFO     | src.models.train_model:trainloop:171 - Epoch 8 train 0.6845 test 0.6756 metric ['0.5600']\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.99it/s]\n",
      "2022-12-19 22:57:11.445 | INFO     | src.models.train_model:trainloop:171 - Epoch 9 train 0.6671 test 0.6604 metric ['0.5887']\n",
      "100%|██████████| 10/10 [01:35<00:00,  9.56s/it]\n"
     ]
    }
   ],
   "source": [
    "model = rnn_models.NLPmodel(config)\n",
    "model = train_model.trainloop(\n",
    "    epochs=10,\n",
    "    model=model,\n",
    "    metrics=[accuracy],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainloader,\n",
    "    test_dataloader=testloader,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=100,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the impact of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 22:59:31.022 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/attention/20221219-2259\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.13it/s]\n",
      "2022-12-19 22:59:44.956 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6716 test 0.6287 metric ['0.6388']\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.71it/s]\n",
      "2022-12-19 22:59:59.227 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.5943 test 0.6190 metric ['0.6737']\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.97it/s]\n",
      "2022-12-19 23:00:13.047 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.5320 test 0.5010 metric ['0.7500']\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.90it/s]\n",
      "2022-12-19 23:00:26.973 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.4765 test 0.5122 metric ['0.7538']\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.24it/s]\n",
      "2022-12-19 23:00:40.418 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.4247 test 0.4875 metric ['0.7588']\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.32it/s]\n",
      "2022-12-19 23:00:53.675 | INFO     | src.models.train_model:trainloop:171 - Epoch 5 train 0.4176 test 0.4503 metric ['0.8113']\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.12it/s]\n",
      "2022-12-19 23:01:07.323 | INFO     | src.models.train_model:trainloop:171 - Epoch 6 train 0.3735 test 0.4460 metric ['0.7750']\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.89it/s]\n",
      "2022-12-19 23:01:21.255 | INFO     | src.models.train_model:trainloop:171 - Epoch 7 train 0.3812 test 0.4102 metric ['0.8163']\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.21it/s]\n",
      "2022-12-19 23:01:34.741 | INFO     | src.models.train_model:trainloop:171 - Epoch 8 train 0.3526 test 0.4461 metric ['0.7812']\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.89it/s]\n",
      "2022-12-19 23:01:48.729 | INFO     | src.models.train_model:trainloop:171 - Epoch 9 train 0.3369 test 0.4052 metric ['0.8037']\n",
      "100%|██████████| 10/10 [02:17<00:00, 13.74s/it]\n"
     ]
    }
   ],
   "source": [
    "model = rnn_models.AttentionNLP(config)\n",
    "model = train_model.trainloop(\n",
    "    epochs=10,\n",
    "    model=model,\n",
    "    metrics=[accuracy],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainloader,\n",
    "    test_dataloader=testloader,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=100,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9384df97cb25cd0ffeadd8ca5fc8c3b92d252d40e81804b4c63c6d046c91939e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
