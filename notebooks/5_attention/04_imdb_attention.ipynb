{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import data_tools, make_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import tokenizer, train_model\n",
    "import torch\n",
    "from src.models import metrics\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:32:20.851 | INFO     | src.data.make_dataset:get_imdb_data:95 - ../../data/raw/aclImdb already exists, skipping download\n",
      "100%|██████████| 25000/25000 [00:08<00:00, 3106.22it/s]\n",
      "100%|██████████| 25000/25000 [00:08<00:00, 2883.28it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../data/raw\"\n",
    "trainpaths, testpaths = make_dataset.get_imdb_data(data_dir)\n",
    "traindataset = data_tools.TextDataset(paths=trainpaths)\n",
    "testdataset = data_tools.TextDataset(paths=testpaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:32:44.504 | INFO     | src.models.tokenizer:build_vocab:23 - Found 79808 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=10000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = tokenizer.Preprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "trainloader = DataLoader(\n",
    "    traindataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testdataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full dataset has 782 batches of 32 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup accuracy and loss_fn (this is a classification problem with two classes, 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "log_dir = Path(\"../../models/attention/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic config. We need to specify the vocabulary lenght for the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import rnn_models\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base NLP model is just a GRU, with an embedding as a first layer.\n",
    "Trainsteps are set to just 100 batches for speedup in the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:34:42.199 | INFO     | src.data.data_tools:dir_add_timestamp:213 - Logging to ../../models/attention/20220524-1134\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.11it/s]\n",
      "2022-05-24 11:35:03.871 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6950 test 0.6931 metric ['0.5150']\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.11it/s]\n",
      "2022-05-24 11:35:25.296 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.6893 test 0.6868 metric ['0.5425']\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.24it/s]\n",
      "2022-05-24 11:35:46.224 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.6726 test 0.6648 metric ['0.6100']\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n",
      "2022-05-24 11:36:06.504 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.6199 test 0.6414 metric ['0.6388']\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.43it/s]\n",
      "2022-05-24 11:36:26.772 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.5427 test 0.5884 metric ['0.7188']\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.16it/s]\n",
      "2022-05-24 11:36:48.019 | INFO     | src.models.train_model:trainloop:171 - Epoch 5 train 0.5127 test 0.4862 metric ['0.7600']\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.42it/s]\n",
      "2022-05-24 11:37:08.308 | INFO     | src.models.train_model:trainloop:171 - Epoch 6 train 0.4415 test 0.5440 metric ['0.7488']\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.97it/s]\n",
      "2022-05-24 11:37:30.442 | INFO     | src.models.train_model:trainloop:171 - Epoch 7 train 0.4270 test 0.4784 metric ['0.7675']\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.44it/s]\n",
      "2022-05-24 11:37:50.582 | INFO     | src.models.train_model:trainloop:171 - Epoch 8 train 0.3867 test 0.4651 metric ['0.7800']\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.49it/s]\n",
      "2022-05-24 11:38:10.819 | INFO     | src.models.train_model:trainloop:171 - Epoch 9 train 0.3853 test 0.4487 metric ['0.7900']\n",
      "100%|██████████| 10/10 [03:28<00:00, 20.83s/it]\n"
     ]
    }
   ],
   "source": [
    "model = rnn_models.NLPmodel(config)\n",
    "model = train_model.trainloop(\n",
    "    epochs=10,\n",
    "    model=model,\n",
    "    metrics=[accuracy],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainloader,\n",
    "    test_dataloader=testloader,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=100,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the impact of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:38:10.857 | INFO     | src.data.data_tools:dir_add_timestamp:213 - Logging to ../../models/attention/20220524-1138\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.17it/s]\n",
      "2022-05-24 11:38:37.862 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6883 test 0.6546 metric ['0.6312']\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.20it/s]\n",
      "2022-05-24 11:39:04.111 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.6011 test 0.5571 metric ['0.7113']\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.24it/s]\n",
      "2022-05-24 11:39:30.221 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.5178 test 0.5309 metric ['0.7425']\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.09it/s]\n",
      "2022-05-24 11:39:57.352 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.4706 test 0.5095 metric ['0.7412']\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.04it/s]\n",
      "2022-05-24 11:40:24.569 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.4319 test 0.5226 metric ['0.7338']\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.26it/s]\n",
      "2022-05-24 11:40:50.783 | INFO     | src.models.train_model:trainloop:171 - Epoch 5 train 0.4201 test 0.4892 metric ['0.7837']\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.28it/s]\n",
      "2022-05-24 11:41:16.748 | INFO     | src.models.train_model:trainloop:171 - Epoch 6 train 0.4092 test 0.4452 metric ['0.7900']\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.16it/s]\n",
      "2022-05-24 11:41:43.338 | INFO     | src.models.train_model:trainloop:171 - Epoch 7 train 0.3688 test 0.3909 metric ['0.8237']\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.23it/s]\n",
      "2022-05-24 11:42:09.698 | INFO     | src.models.train_model:trainloop:171 - Epoch 8 train 0.3558 test 0.4228 metric ['0.7950']\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.29it/s]\n",
      "2022-05-24 11:42:35.511 | INFO     | src.models.train_model:trainloop:171 - Epoch 9 train 0.3321 test 0.4408 metric ['0.8013']\n",
      "100%|██████████| 10/10 [04:24<00:00, 26.42s/it]\n"
     ]
    }
   ],
   "source": [
    "model = rnn_models.AttentionNLP(config)\n",
    "model = train_model.trainloop(\n",
    "    epochs=10,\n",
    "    model=model,\n",
    "    metrics=[accuracy],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainloader,\n",
    "    test_dataloader=testloader,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=100,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
