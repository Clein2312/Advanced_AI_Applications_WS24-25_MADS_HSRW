{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.9/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='imdb.gin', imports=[], includes=[])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import data_tools, make_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import tokenizer, train_model\n",
    "import torch\n",
    "from src.models import metrics\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "from src.models.rnn_models import NLPmodel, AttentionNLP\n",
    "import gin\n",
    "gin.parse_config_file(\"imdb.gin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 09:18:32.773 | INFO     | src.data.make_dataset:get_imdb_data:96 - ../../data/raw/aclImdb already exists, skipping download\n",
      "100%|██████████| 25000/25000 [00:53<00:00, 466.42it/s]\n",
      "100%|██████████| 25000/25000 [00:52<00:00, 479.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../data/raw\"\n",
    "trainpaths, testpaths = make_dataset.get_imdb_data(data_dir)\n",
    "traindataset = data_tools.TextDataset(paths=trainpaths)\n",
    "testdataset = data_tools.TextDataset(paths=testpaths)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 09:20:27.308 | INFO     | src.models.tokenizer:build_vocab:27 - Found 79808 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of vocab is 10002\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=10000)\n",
    "print(f\"Lenght of vocab is {len(v)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = tokenizer.Preprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "trainloader = DataLoader(\n",
    "    traindataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testdataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full dataset has 782 batches of 32 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup accuracy and loss_fn (this is a classification problem with two classes, 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "log_dir = Path(\"../../models/attention/\").resolve()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic config. We need to specify the vocabulary lenght for the embedding layer.\n",
    "Trainsteps are set to just 100 batches for speedup in the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 09:20:28.362 | INFO     | src.settings:check_path:45 - logdir did not exist. Creating at /workspaces/ML22/models/attention.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "epochs: 10\n",
       "metrics: [Accuracy]\n",
       "logdir: /workspaces/ML22/models/attention\n",
       "train_steps: 100\n",
       "valid_steps: 25\n",
       "tunewriter: ['tensorboard', 'gin']\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: {'save': False, 'verbose': True, 'patience': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.settings import TrainerSettings\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=100,\n",
    "    valid_steps=25,\n",
    "    tunewriter=[\"tensorboard\", \"gin\"],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gin.get_bindings(\"NLPmodel\")[\"config\"][\"vocab\"] == len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLPmodel(\n",
       "  (emb): Embedding(10002, 128)\n",
       "  (rnn): GRU(128, 128, num_layers=3, batch_first=True, dropout=0.1)\n",
       "  (linear): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NLPmodel()\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base NLP model is just a GRU, with an embedding as a first layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 09:20:29.095 | INFO     | src.data.data_tools:dir_add_timestamp:137 - Logging to /workspaces/ML22/models/attention/20230526-0920\n",
      "2023-05-26 09:20:29.118 | INFO     | src.models.train_model:__init__:109 - Found earlystop_kwargs in TrainerSettings. Set to None if you dont want earlystopping.\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:38<00:00,  2.58it/s]\n",
      "2023-05-26 09:21:10.751 | INFO     | src.models.train_model:report:207 - Epoch 0 train 0.6953 test 0.6985 metric ['0.5050']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:24<00:00,  4.04it/s]\n",
      "2023-05-26 09:21:37.228 | INFO     | src.models.train_model:report:207 - Epoch 1 train 0.6900 test 0.6845 metric ['0.5625']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:33<00:00,  3.01it/s]\n",
      "2023-05-26 09:22:12.359 | INFO     | src.models.train_model:report:207 - Epoch 2 train 0.6827 test 0.6781 metric ['0.5637']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:28<00:00,  3.47it/s]\n",
      "2023-05-26 09:22:42.848 | INFO     | src.models.train_model:report:207 - Epoch 3 train 0.6516 test 0.6807 metric ['0.6312']\n",
      "2023-05-26 09:22:42.851 | INFO     | src.models.train_model:__call__:244 - best loss: 0.67807936668396, current loss 0.680717. Counter 1.000000/10.\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:29<00:00,  3.35it/s]\n",
      "2023-05-26 09:23:14.720 | INFO     | src.models.train_model:report:207 - Epoch 4 train 0.5760 test 0.5618 metric ['0.7338']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:25<00:00,  3.95it/s]\n",
      "2023-05-26 09:23:42.042 | INFO     | src.models.train_model:report:207 - Epoch 5 train 0.5026 test 0.4922 metric ['0.7588']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:33<00:00,  2.98it/s]\n",
      "2023-05-26 09:24:17.494 | INFO     | src.models.train_model:report:207 - Epoch 6 train 0.4655 test 0.5007 metric ['0.7450']\n",
      "2023-05-26 09:24:17.498 | INFO     | src.models.train_model:__call__:244 - best loss: 0.49217348217964174, current loss 0.500738. Counter 1.000000/10.\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:30<00:00,  3.29it/s]\n",
      "2023-05-26 09:24:49.825 | INFO     | src.models.train_model:report:207 - Epoch 7 train 0.4332 test 0.4483 metric ['0.7863']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:35<00:00,  2.81it/s]\n",
      "2023-05-26 09:25:27.765 | INFO     | src.models.train_model:report:207 - Epoch 8 train 0.3999 test 0.4433 metric ['0.7937']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:29<00:00,  3.34it/s]\n",
      "2023-05-26 09:25:59.854 | INFO     | src.models.train_model:report:207 - Epoch 9 train 0.3633 test 0.4311 metric ['0.8100']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [05:30<00:00, 33.06s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer = train_model.Trainer(\n",
    "    model=model, \n",
    "    settings=settings, \n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam, \n",
    "    traindataloader=trainloader, \n",
    "    validdataloader=testloader, \n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "trainer.loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the impact of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"imdb.gin\")\n",
    "attentionmodel = AttentionNLP()\n",
    "attentiontrainer = train_model.Trainer(\n",
    "    model=attentionmodel, \n",
    "    settings=settings, \n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam, \n",
    "    traindataloader=trainloader, \n",
    "    validdataloader=testloader, \n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "attentiontrainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9384df97cb25cd0ffeadd8ca5fc8c3b92d252d40e81804b4c63c6d046c91939e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
