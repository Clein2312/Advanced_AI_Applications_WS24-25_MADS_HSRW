{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from trax import layers as tl\n",
    "from trax.shapes import signature\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.models.build import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Convolutions\n",
    "We can easily create new layers by combining the base layers from trax. You will find everything you know from torch.\n",
    "For example, a Conv2D layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 128, 128, 64), dtype:float32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(32, 128, 128, 3)\n",
    "conv = tl.Conv(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"SAME\")\n",
    "conv.init_weights_and_state(signature(X))\n",
    "\n",
    "yhat = conv(X)\n",
    "signature(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a model with three serial Conv2d layers as we have built in the convolutions lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Conv                (32, 128, 128, 3)  (float64) | (32, 64, 64, 64)   (float32)\n",
      "(1) Relu                (32, 64, 64, 64)   (float32) | (32, 64, 64, 64)   (float32)\n",
      "(2) Conv                (32, 64, 64, 64)   (float32) | (32, 32, 32, 128)  (float32)\n",
      "(3) Relu                (32, 32, 32, 128)  (float32) | (32, 32, 32, 128)  (float32)\n",
      "(4) Conv                (32, 32, 32, 128)  (float32) | (32, 16, 16, 256)  (float32)\n",
      "(5) Relu                (32, 16, 16, 256)  (float32) | (32, 16, 16, 256)  (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 16, 16, 256), dtype:float32}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cb.Serial(\n",
    "    tl.Conv(filters=64, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    "    tl.Conv(filters=128, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    "    tl.Conv(filters=256, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    ")\n",
    "model.init_weights_and_state(X)\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 RNNs\n",
    "Let's implement an Embedding + GRU model, like we built in the Attention lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_1000_128  (32, 100)          ( int64 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) Dense_2             (32, 100, 128)     (float32) | (32, 100, 2)       (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 100, 2), dtype:float32}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(0, 1000, size=(32, 100))\n",
    "\n",
    "model = cb.Serial(\n",
    "    tl.Embedding(vocab_size=1000, d_feature=128), tl.GRU(n_units=128), tl.Dense(2)\n",
    ")\n",
    "model.init_weights_and_state(signature(X))\n",
    "\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap this in a function, so we can pass the vocab_size and the units as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape(\"bs->bsd\")\n",
    "def EmbGRU(vocab_size: int, d_feature: int, d_out: int):\n",
    "\n",
    "    model = cb.Serial(\n",
    "        tl.Embedding(vocab_size=vocab_size, d_feature=d_feature),\n",
    "        tl.GRU(n_units=d_feature),\n",
    "        tl.Dense(d_out),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 The assert_shape decorator\n",
    "Note how we use an `@assert_shape` decorator. This is a very nice safety check.\n",
    "\n",
    "From the [trax source code](https://github.com/google/trax/blob/master/trax/layers/assert_shape.py#L70):\n",
    "\n",
    "```python\n",
    "  Examples:\n",
    "  # In Dense layer there is a single input and single output; the last dimension\n",
    "  # may change in size, while the sizes of all previous dimensions, marked by\n",
    "  # an ellipsis, will stay the same.\n",
    "  @assert_shape('...a->...b')\n",
    "  class Dense(base.Layer):\n",
    "    (...)\n",
    "\n",
    "  # DotProductCausalAttention takes three tensors as input: Queries, Keys, and\n",
    "  # Values, and outputs a single tensor. Sizes of the first two dimensions in\n",
    "  # all those tensors must match, while the last dimension must match only\n",
    "  # between Queries and Keys, and separately between Values and output tensor.\n",
    "  @assert_shape('blk,blk,bld->bld')\n",
    "  class DotProductCausalAttention(base.Layer):\n",
    "    (...)\n",
    "\n",
    "  # assert_shape can also be placed before the function returning base.Layer.\n",
    "  @assert_shape('...d->...')\n",
    "  def ReduceSum():\n",
    "    return Fn('ReduceSum', lambda x: jnp.sum(x, axis=-1, keepdims=False))\n",
    "```\n",
    "\n",
    "Our EmbGRU models expects as input a Tensor with dimensions (batch, sequencelenght) denoted with `bs`.\n",
    "The output should be (batch, sequencelenght, dimension) denoted with `bsd`.\n",
    "`@assert_shape` will check for us if this is correct.\n",
    "\n",
    "So this works:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_1000_128  (32, 100)          ( int64 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) Dense_2             (32, 100, 128)     (float32) | (32, 100, 2)       (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 100, 2), dtype:float32}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EmbGRU(vocab_size=1000, d_feature=128, d_out=2)\n",
    "model.init_weights_and_state(signature(X))\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this fails! Can you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception passing through layer  (in _forward_abstract):\n",
      "  layer created in file [...]/T/ipykernel_96134/1412570724.py, line 2\n",
      "  layer input shapes: [[[237 569 109]\n",
      "  [114 882 173]\n",
      "  [241 634 559]\n",
      "  [926 588  17]\n",
      "  [169 570 914]\n",
      "  [331 933 850]\n",
      "  [334 711 637]\n",
      "  [860 511 426]\n",
      "  [586 712 674]\n",
      "  [874 571  34]]\n",
      "\n",
      " [[587 938 942]\n",
      "  [373 962 606]\n",
      "  [429 675 213]\n",
      "  [246 140  64]\n",
      "  [134 897 676]\n",
      "  [158 223 257]\n",
      "  [412 700 492]\n",
      "  [455 634 100]\n",
      "  [612  86 257]\n",
      "  [861  96 685]]\n",
      "\n",
      " [[448 555 593]\n",
      "  [761 266 233]\n",
      "  [631 500 286]\n",
      "  [  9 289 471]\n",
      "  [324 307 114]\n",
      "  [808 987 820]\n",
      "  [785 718 915]\n",
      "  [451 550 418]\n",
      "  [414 916 930]\n",
      "  [341 848 632]]\n",
      "\n",
      " [[967 634 301]\n",
      "  [275 177 208]\n",
      "  [195 101 850]\n",
      "  [345 672 437]\n",
      "  [635 145 355]\n",
      "  [556 143 300]\n",
      "  [450 797 401]\n",
      "  [411  81 685]\n",
      "  [ 76 277 585]\n",
      "  [220 397 811]]\n",
      "\n",
      " [[835 489 395]\n",
      "  [943 748  65]\n",
      "  [813 322 178]\n",
      "  [ 86 842 162]\n",
      "  [ 50 317   0]\n",
      "  [748 569  75]\n",
      "  [296 183 630]\n",
      "  [119  75 213]\n",
      "  [824 388 267]\n",
      "  [652 249  76]]\n",
      "\n",
      " [[779 282 368]\n",
      "  [248 929 563]\n",
      "  [337 664 694]\n",
      "  [721 349 151]\n",
      "  [609 121 375]\n",
      "  [ 84 337 559]\n",
      "  [616 320 809]\n",
      "  [247 629 449]\n",
      "  [771 823 357]\n",
      "  [587 705 187]]\n",
      "\n",
      " [[333 185 888]\n",
      "  [455 717 694]\n",
      "  [657 938 992]\n",
      "  [337 196 178]\n",
      "  [614 804 132]\n",
      "  [237 193 832]\n",
      "  [558 415 845]\n",
      "  [204 706 286]\n",
      "  [597 774 408]\n",
      "  [  8 579 115]]\n",
      "\n",
      " [[ 25 914 489]\n",
      "  [301 674 668]\n",
      "  [ 68 733 784]\n",
      "  [559 814 643]\n",
      "  [499 652 609]\n",
      "  [629  81 507]\n",
      "  [814 510 410]\n",
      "  [628 396 526]\n",
      "  [947 150 193]\n",
      "  [823 555  51]]\n",
      "\n",
      " [[145 522   9]\n",
      "  [134  47 326]\n",
      "  [496 101 662]\n",
      "  [435 553 939]\n",
      "  [496 520 557]\n",
      "  [849 966 747]\n",
      "  [732 781 847]\n",
      "  [  8 651 379]\n",
      "  [717 330 415]\n",
      "  [329 259 784]]\n",
      "\n",
      " [[711 410  77]\n",
      "  [962  74 802]\n",
      "  [711 828 352]\n",
      "  [873 686 300]\n",
      "  [ 84 914 811]\n",
      "  [256 383 129]\n",
      "  [340  32 368]\n",
      "  [ 53 214 341]\n",
      "  [ 64 882 166]\n",
      "  [516 698 628]]\n",
      "\n",
      " [[762  30 359]\n",
      "  [253 881 113]\n",
      "  [384 791 501]\n",
      "  [368 774 399]\n",
      "  [559 442 461]\n",
      "  [506 719  85]\n",
      "  [624 533 635]\n",
      "  [237 535 271]\n",
      "  [851  72  48]\n",
      "  [436 233 637]]\n",
      "\n",
      " [[649 201 430]\n",
      "  [220 673 212]\n",
      "  [690 368 120]\n",
      "  [321 935 784]\n",
      "  [148 900 845]\n",
      "  [737 545  32]\n",
      "  [596 433 999]\n",
      "  [935 611 256]\n",
      "  [914 369 121]\n",
      "  [771 859 259]]\n",
      "\n",
      " [[891 392 960]\n",
      "  [860 237 224]\n",
      "  [634 464 939]\n",
      "  [253 196  10]\n",
      "  [264 229 527]\n",
      "  [594 288 560]\n",
      "  [339 307 622]\n",
      "  [318 764 342]\n",
      "  [848 558  26]\n",
      "  [429  42 216]]\n",
      "\n",
      " [[102  32 580]\n",
      "  [241 697 418]\n",
      "  [664 896 868]\n",
      "  [ 56 535 912]\n",
      "  [603 485 644]\n",
      "  [ 40 988 414]\n",
      "  [525 235  81]\n",
      "  [550 602 825]\n",
      "  [ 17 723 149]\n",
      "  [528  24 881]]\n",
      "\n",
      " [[901 433 476]\n",
      "  [ 17 166 917]\n",
      "  [ 33 849  68]\n",
      "  [ 51 449 703]\n",
      "  [246 614 547]\n",
      "  [637 701 466]\n",
      "  [488 114 912]\n",
      "  [844  15 254]\n",
      "  [639 885 955]\n",
      "  [609 446 890]]\n",
      "\n",
      " [[654 715 274]\n",
      "  [602 578 291]\n",
      "  [199 758 953]\n",
      "  [778 857 586]\n",
      "  [559 487 209]\n",
      "  [326 485 981]\n",
      "  [169 688 434]\n",
      "  [843 121 680]\n",
      "  [841  26 390]\n",
      "  [610 161 423]]\n",
      "\n",
      " [[ 72 659 503]\n",
      "  [710 566 807]\n",
      "  [562 941 425]\n",
      "  [369 425 734]\n",
      "  [ 81 959 458]\n",
      "  [416 288 799]\n",
      "  [991 808 593]\n",
      "  [609 619 499]\n",
      "  [718 683 855]\n",
      "  [687 182 687]]\n",
      "\n",
      " [[794 840  86]\n",
      "  [110 547 525]\n",
      "  [540 462 763]\n",
      "  [658 751 905]\n",
      "  [869 474 501]\n",
      "  [267 878 872]\n",
      "  [953 452 936]\n",
      "  [522  98 983]\n",
      "  [  0 162 317]\n",
      "  [336 201 539]]\n",
      "\n",
      " [[399 296 185]\n",
      "  [939  36 360]\n",
      "  [ 63 845  25]\n",
      "  [553  49 360]\n",
      "  [438 564 118]\n",
      "  [568 740 676]\n",
      "  [609 595  87]\n",
      "  [499 199 610]\n",
      "  [895 603 900]\n",
      "  [346  59 610]]\n",
      "\n",
      " [[444 337 305]\n",
      "  [437 105  53]\n",
      "  [587 222 503]\n",
      "  [593 514 607]\n",
      "  [446 114 740]\n",
      "  [383 590 821]\n",
      "  [220 276 536]\n",
      "  [426 541  64]\n",
      "  [356 751 819]\n",
      "  [ 82 624 256]]\n",
      "\n",
      " [[672 406 245]\n",
      "  [211 652 662]\n",
      "  [173 873 430]\n",
      "  [510 285 493]\n",
      "  [ 33 761 309]\n",
      "  [798 638 768]\n",
      "  [732 534 312]\n",
      "  [904 194 354]\n",
      "  [772 574 525]\n",
      "  [496 662 245]]\n",
      "\n",
      " [[858 711 779]\n",
      "  [572 564 966]\n",
      "  [471 822 336]\n",
      "  [933 638 720]\n",
      "  [897 699 150]\n",
      "  [300  39 702]\n",
      "  [280 801 996]\n",
      "  [778 195 268]\n",
      "  [532 227 819]\n",
      "  [371 331 738]]\n",
      "\n",
      " [[118  26 628]\n",
      "  [250 533 365]\n",
      "  [619 975 106]\n",
      "  [512 465 350]\n",
      "  [942 480 857]\n",
      "  [593 760 391]\n",
      "  [321 874  26]\n",
      "  [615 564  21]\n",
      "  [967 945 671]\n",
      "  [574 876 373]]\n",
      "\n",
      " [[125  74 799]\n",
      "  [533 735 479]\n",
      "  [378 149 837]\n",
      "  [446 446 799]\n",
      "  [710 574 452]\n",
      "  [393   4 375]\n",
      "  [963 548 214]\n",
      "  [406  47 583]\n",
      "  [222 527 926]\n",
      "  [319 553 500]]\n",
      "\n",
      " [[714 382 395]\n",
      "  [281 144 686]\n",
      "  [203 661 213]\n",
      "  [ 14 479 441]\n",
      "  [  7 667 418]\n",
      "  [682 528 362]\n",
      "  [298 528  49]\n",
      "  [627 168  35]\n",
      "  [ 62 404 184]\n",
      "  [617 559 667]]\n",
      "\n",
      " [[ 22 830 729]\n",
      "  [175 465 702]\n",
      "  [938 634 584]\n",
      "  [359 863 410]\n",
      "  [932 574 975]\n",
      "  [932 590 739]\n",
      "  [997 257 307]\n",
      "  [534   5 257]\n",
      "  [824 109 534]\n",
      "  [221 119 976]]\n",
      "\n",
      " [[771 818 580]\n",
      "  [737 862 764]\n",
      "  [845 777 289]\n",
      "  [723 249 211]\n",
      "  [165 783 822]\n",
      "  [750 572 731]\n",
      "  [243 296 433]\n",
      "  [786 890 769]\n",
      "  [993 296 230]\n",
      "  [114 689 453]]\n",
      "\n",
      " [[573 643 364]\n",
      "  [415  81 685]\n",
      "  [102 419 359]\n",
      "  [479 919 513]\n",
      "  [588  83 442]\n",
      "  [933 886 834]\n",
      "  [182 291 762]\n",
      "  [917 624 725]\n",
      "  [639 526 952]\n",
      "  [143 162  50]]\n",
      "\n",
      " [[133  89 315]\n",
      "  [562 631 807]\n",
      "  [555 856 957]\n",
      "  [327 650 588]\n",
      "  [ 93 516 168]\n",
      "  [404  30 911]\n",
      "  [951 210 943]\n",
      "  [568 470 230]\n",
      "  [263 697 722]\n",
      "  [278 578 388]]\n",
      "\n",
      " [[740 981 947]\n",
      "  [247  49 862]\n",
      "  [184 587 473]\n",
      "  [818 266 826]\n",
      "  [  5 587 831]\n",
      "  [945 491 296]\n",
      "  [151 740 976]\n",
      "  [541 214 761]\n",
      "  [489 811 361]\n",
      "  [660 480  28]]\n",
      "\n",
      " [[564 326 629]\n",
      "  [398 892 473]\n",
      "  [664 912 501]\n",
      "  [280 806  69]\n",
      "  [298 593 712]\n",
      "  [900 164  15]\n",
      "  [296 824 674]\n",
      "  [913 180 283]\n",
      "  [610 702 267]\n",
      "  [ 76 303 397]]\n",
      "\n",
      " [[837 713 340]\n",
      "  [391  67 641]\n",
      "  [301 224 565]\n",
      "  [853 570 904]\n",
      "  [933 315 316]\n",
      "  [418 991 673]\n",
      "  [420 438 169]\n",
      "  [730 536 194]\n",
      "  [585 153 733]\n",
      "  [991 733 568]]]\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 426, in abstract_eval_fun\n",
      "    _, avals_out, _ = trace_to_jaxpr_dynamic(\n",
      "\n",
      "  File [...]/jax/_src/profiler.py, line 206, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 1620, in trace_to_jaxpr_dynamic\n",
      "    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 1657, in trace_to_subjaxpr_dynamic\n",
      "    ans = fun.call_wrapped(*in_tracers_)\n",
      "\n",
      "  File [...]/site-packages/jax/linear_util.py, line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "\n",
      "  File [...]/site-packages/jax/linear_util.py, line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "\n",
      "LayerError: Exception passing through layer  (in pure_fn):\n",
      "  layer created in file [...]/T/ipykernel_96134/1412570724.py, line 2\n",
      "  layer input shapes: ShapeDtype{shape:(32, 10, 3), dtype:int32}\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 280, in forward\n",
      "    check_shape(x.shape, spec)\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 248, in check_shape\n",
      "    assert_equal(len(shape), len(spec))\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 244, in assert_equal\n",
      "    assert_true(a == b)\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 239, in assert_true\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: AssertShape Error. Expected ['bs'], got [(32, 10, 3)] with dict {}. Defined at /var/folders/27/8l0tbkzx7px4b1vn082g66qc0000gn/T/ipykernel_96134/2254428536.py:1 function input\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(0, 1000, size=(32, 10, 3))\n",
    "model = EmbGRU(vocab_size=1000, d_feature=128, d_out=2)\n",
    "try:\n",
    "    model.init_weights_and_state(X)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Implementing your own layers\n",
    "If we would like to implement our own layers, we could do that too.\n",
    "\n",
    "Again, from the [source code of trax](https://github.com/google/trax/blob/master/trax/layers/base.py#L747):\n",
    "\n",
    "```python\n",
    "def Fn(name, f, n_out=1):  # pylint: disable=invalid-name\n",
    "  \"\"\"Returns a layer with no weights that applies the function `f`.\n",
    "\n",
    "  `f` can take and return any number of arguments, and takes only positional\n",
    "  arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n",
    "  The following, for example, would create a layer that takes two inputs and\n",
    "  returns two outputs -- element-wise sums and maxima:\n",
    "\n",
    "      `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n",
    "\n",
    "  The layer's number of inputs (`n_in`) is automatically set to number of\n",
    "  positional arguments in `f`, but you must explicitly set the number of\n",
    "  outputs (`n_out`) whenever it's not the default value 1.\n",
    "\n",
    "  Args:\n",
    "    name: Class-like name for the resulting layer; for use in debugging.\n",
    "    f: Pure function from input tensors to output tensors, where each input\n",
    "        tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n",
    "        Output tensors must be packaged as specified in the `Layer` class\n",
    "        docstring.\n",
    "    n_out: Number of outputs promised by the layer; default value 1.\n",
    "\n",
    "  Returns:\n",
    "    Layer executing the function `f`.\n",
    "  \"\"\"\n",
    "  ```\n",
    "\n",
    "  Let's implement our own Hadamard product.\n",
    "  You might remember from the RNN lesson, that we used this for the gates:\n",
    "\n",
    "$$h_t = \\Gamma \\otimes h_{t-1}$$\n",
    "\n",
    "where $\\Gamma$ is the gate (which has the same size as $h$ and values between 0 and 1), $h$ is the hidden state, and $\\otimes$ the Hadamard product. For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.04 \\\\\n",
    "0.25 & -0.48\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.01 \\\\\n",
    "0.5 & 0.2\n",
    "\\end{bmatrix}\n",
    "\\otimes\n",
    "\\begin{bmatrix}\n",
    "1.0 & 2.0 \\\\\n",
    "0.5 & -2.4\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = tl.Softmax(axis=-1)\n",
    "X = np.random.rand(32, 20)\n",
    "gate = softmax(X)\n",
    "\n",
    "out = jnp.multiply(X, gate)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jnp` function is kind of simple. But we want to make sure this is part of the backpropagation of our model.\n",
    "We make it into a proper layer with `tl.Fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hadamard():\n",
    "    def f(x0, x1):\n",
    "        return jnp.multiply(x0, x1)\n",
    "\n",
    "    return tl.Fn(\"Hadamard\", f, n_out=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use is as part of a model.\n",
    "For example, let's implement the Gated Linear Unit:\n",
    "$$GLU(X) = \\sigma(W_1 X + b_1) \\otimes (W_2 X + b_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 128), dtype:float32}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate = cb.Serial(tl.Dense(128), tl.Softmax(axis=-1))\n",
    "\n",
    "model = cb.Serial(\n",
    "    cb.Branch(gate, tl.Dense(128)),\n",
    "    Hadamard(),\n",
    ")\n",
    "model.init_weights_and_state(signature(X))\n",
    "yhat = model(X)\n",
    "signature(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, wrap it inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape(\"bd->bd\")\n",
    "def GLU(units: int):\n",
    "    gate = cb.Serial(tl.Dense(units), tl.Softmax(axis=-1))\n",
    "\n",
    "    model = cb.Serial(\n",
    "        cb.Branch(gate, tl.Dense(units)),\n",
    "        Hadamard(),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
