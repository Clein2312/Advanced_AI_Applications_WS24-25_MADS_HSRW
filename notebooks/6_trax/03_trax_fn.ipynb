{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from trax import layers as tl\n",
    "from trax.shapes import signature\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.models.build import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Convolutions\n",
    "We can easily create new layers by combining the base layers from trax. You will find everything you know from torch.\n",
    "For example, a [Conv2D layer](https://github.com/google/trax/blob/master/trax/layers/convolution.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 128, 128, 64), dtype:float32}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(32, 128, 128, 3)\n",
    "conv = tl.Conv(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"SAME\")\n",
    "conv.init_weights_and_state(signature(X))\n",
    "\n",
    "yhat = conv(X)\n",
    "signature(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trax in general implements the TensorFlow API, so you can always read a bit more on the excellent [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "\n",
    "We can extent this one-layers model into a model with three serial Conv2d layers as we have built in the convolutions lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Conv                (32, 128, 128, 3)  (float64) | (32, 64, 64, 64)   (float32)\n",
      "(1) Relu                (32, 64, 64, 64)   (float32) | (32, 64, 64, 64)   (float32)\n",
      "(2) Conv                (32, 64, 64, 64)   (float32) | (32, 32, 32, 128)  (float32)\n",
      "(3) Relu                (32, 32, 32, 128)  (float32) | (32, 32, 32, 128)  (float32)\n",
      "(4) Conv                (32, 32, 32, 128)  (float32) | (32, 16, 16, 256)  (float32)\n",
      "(5) Relu                (32, 16, 16, 256)  (float32) | (32, 16, 16, 256)  (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 16, 16, 256), dtype:float32}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cb.Serial(\n",
    "    tl.Conv(filters=64, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    "    tl.Conv(filters=128, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    "    tl.Conv(filters=256, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    ")\n",
    "model.init_weights_and_state(X)\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a custom \"summary\" function for Trax models. It does not work (yet) for parallel layers, but I thought it would help some of you with building models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 RNNs\n",
    "Let's implement an Embedding + GRU model, like we have built in the Attention lesson #5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_1000_128  (32, 100)          ( int64 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) Dense_2             (32, 100, 128)     (float32) | (32, 100, 2)       (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 100, 2), dtype:float32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(0, 1000, size=(32, 100))\n",
    "\n",
    "model = cb.Serial(\n",
    "    tl.Embedding(vocab_size=1000, d_feature=128), tl.GRU(n_units=128), tl.Dense(2)\n",
    ")\n",
    "model.init_weights_and_state(signature(X))\n",
    "\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap this in a function, so we can pass the vocab_size and the units as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape(\"bs->bsd\")\n",
    "def EmbGRU(vocab_size: int, d_feature: int, d_out: int):\n",
    "\n",
    "    model = cb.Serial(\n",
    "        tl.Embedding(vocab_size=vocab_size, d_feature=d_feature),\n",
    "        tl.GRU(n_units=d_feature),\n",
    "        tl.Dense(d_out),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 The assert_shape decorator\n",
    "Note how we use an `@assert_shape` decorator. This is a very nice safety check.\n",
    "\n",
    "From the [trax source code](https://github.com/google/trax/blob/master/trax/layers/assert_shape.py#L70):\n",
    "\n",
    "```python\n",
    "  Examples:\n",
    "  # In Dense layer there is a single input and single output; the last dimension\n",
    "  # may change in size, while the sizes of all previous dimensions, marked by\n",
    "  # an ellipsis, will stay the same.\n",
    "  @assert_shape('...a->...b')\n",
    "  class Dense(base.Layer):\n",
    "    (...)\n",
    "\n",
    "  # DotProductCausalAttention takes three tensors as input: Queries, Keys, and\n",
    "  # Values, and outputs a single tensor. Sizes of the first two dimensions in\n",
    "  # all those tensors must match, while the last dimension must match only\n",
    "  # between Queries and Keys, and separately between Values and output tensor.\n",
    "  @assert_shape('blk,blk,bld->bld')\n",
    "  class DotProductCausalAttention(base.Layer):\n",
    "    (...)\n",
    "\n",
    "  # assert_shape can also be placed before the function returning base.Layer.\n",
    "  @assert_shape('...d->...')\n",
    "  def ReduceSum():\n",
    "    return Fn('ReduceSum', lambda x: jnp.sum(x, axis=-1, keepdims=False))\n",
    "```\n",
    "\n",
    "Our EmbGRU models expects as input a Tensor with dimensions (batch, sequencelenght) denoted with `bs`.\n",
    "The output should be (batch, sequencelenght, dimension) denoted with `bsd`.\n",
    "`@assert_shape` will check for us if this is correct.\n",
    "\n",
    "We can use any letter we like. Trax will simple check that the input has two dimensions, and that the output has exactly the same dimensions plus an additional third dimension.\n",
    "\n",
    "So this works:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_1000_128  (32, 100)          ( int64 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) Dense_2             (32, 100, 128)     (float32) | (32, 100, 2)       (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 100, 2), dtype:float32}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EmbGRU(vocab_size=1000, d_feature=128, d_out=2)\n",
    "model.init_weights_and_state(signature(X))\n",
    "summary(model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this fails! Can you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception passing through layer  (in _forward_abstract):\n",
      "  layer created in file [...]/T/ipykernel_75043/461658037.py, line 2\n",
      "  layer input shapes: [[[171 621 716]\n",
      "  [ 46 744 995]\n",
      "  [990 738 611]\n",
      "  [838 528 468]\n",
      "  [325 312 770]\n",
      "  [928 973 349]\n",
      "  [221 892 235]\n",
      "  [893 932 221]\n",
      "  [844 736 905]\n",
      "  [773 715 248]]\n",
      "\n",
      " [[570 658 219]\n",
      "  [946 555 602]\n",
      "  [745 718  57]\n",
      "  [918 716 864]\n",
      "  [ 62 979 781]\n",
      "  [ 69  12 673]\n",
      "  [792 740  14]\n",
      "  [408 840 683]\n",
      "  [358 257 464]\n",
      "  [ 55 982 493]]\n",
      "\n",
      " [[610 526 319]\n",
      "  [986   0 711]\n",
      "  [ 79 652 677]\n",
      "  [546 138 792]\n",
      "  [475 720  60]\n",
      "  [347 975 751]\n",
      "  [774 230 994]\n",
      "  [828 145 111]\n",
      "  [177  54 380]\n",
      "  [325  42 442]]\n",
      "\n",
      " [[169 387 481]\n",
      "  [705 277  83]\n",
      "  [160 635 304]\n",
      "  [957 227 121]\n",
      "  [ 99 505   4]\n",
      "  [939 861  12]\n",
      "  [775 309 361]\n",
      "  [342 816 368]\n",
      "  [934 245 205]\n",
      "  [951 361 475]]\n",
      "\n",
      " [[613  55 568]\n",
      "  [  0 690 950]\n",
      "  [726 335 100]\n",
      "  [440 855 475]\n",
      "  [884 312 258]\n",
      "  [847 873 255]\n",
      "  [829 586 699]\n",
      "  [149  69 637]\n",
      "  [734 326 819]\n",
      "  [739 772 270]]\n",
      "\n",
      " [[297 938 358]\n",
      "  [963 213 392]\n",
      "  [174 234   2]\n",
      "  [177 401 740]\n",
      "  [ 49 788 298]\n",
      "  [356  34 867]\n",
      "  [979 803  32]\n",
      "  [240 881 509]\n",
      "  [243 153 702]\n",
      "  [115 228  54]]\n",
      "\n",
      " [[253 658  48]\n",
      "  [455 527  66]\n",
      "  [ 82 375 247]\n",
      "  [708 922  72]\n",
      "  [749 180 831]\n",
      "  [643 358 288]\n",
      "  [616 338 651]\n",
      "  [905 849 473]\n",
      "  [350 705   8]\n",
      "  [835 556 334]]\n",
      "\n",
      " [[829 110 884]\n",
      "  [785 179 711]\n",
      "  [866 711  95]\n",
      "  [222 160 415]\n",
      "  [328 276 488]\n",
      "  [ 56 129 995]\n",
      "  [109  26 380]\n",
      "  [803 552 583]\n",
      "  [536 567 730]\n",
      "  [846 185 248]]\n",
      "\n",
      " [[747 255 842]\n",
      "  [869 854 351]\n",
      "  [868 305 994]\n",
      "  [671 398 574]\n",
      "  [365 638 829]\n",
      "  [414 370 100]\n",
      "  [917 117  95]\n",
      "  [114 174 297]\n",
      "  [319 320 210]\n",
      "  [981 886 476]]\n",
      "\n",
      " [[820 890 919]\n",
      "  [744 868 738]\n",
      "  [ 96 263  82]\n",
      "  [295 921 492]\n",
      "  [115 652 548]\n",
      "  [861 219 466]\n",
      "  [627  30 856]\n",
      "  [993 637 514]\n",
      "  [800 139 663]\n",
      "  [533   4 796]]\n",
      "\n",
      " [[498 105  23]\n",
      "  [209 668 849]\n",
      "  [856 989 749]\n",
      "  [858 471 359]\n",
      "  [155 591   4]\n",
      "  [954 328 748]\n",
      "  [965 922 997]\n",
      "  [588  18 948]\n",
      "  [327 836 405]\n",
      "  [224 748 265]]\n",
      "\n",
      " [[140 789 414]\n",
      "  [626 920 626]\n",
      "  [217  78 618]\n",
      "  [417 250 519]\n",
      "  [321 669 775]\n",
      "  [290 987 911]\n",
      "  [197 824 472]\n",
      "  [616 602 791]\n",
      "  [170  43  91]\n",
      "  [942 776 947]]\n",
      "\n",
      " [[ 93  64 724]\n",
      "  [888 144 294]\n",
      "  [457 690 869]\n",
      "  [751  49 484]\n",
      "  [987 683 768]\n",
      "  [161 582 177]\n",
      "  [ 18 252 279]\n",
      "  [651 734 480]\n",
      "  [587 793 274]\n",
      "  [646 258 986]]\n",
      "\n",
      " [[949  61 794]\n",
      "  [666 838 255]\n",
      "  [118 383 717]\n",
      "  [224 237 934]\n",
      "  [ 88 245 803]\n",
      "  [600   7 515]\n",
      "  [889 160 752]\n",
      "  [990 318 172]\n",
      "  [671  29 766]\n",
      "  [419  31 464]]\n",
      "\n",
      " [[384 136 169]\n",
      "  [735 737 766]\n",
      "  [547 192 329]\n",
      "  [ 52 238 525]\n",
      "  [599 853 449]\n",
      "  [788 752 980]\n",
      "  [219  98  83]\n",
      "  [ 17 894 853]\n",
      "  [ 26 349  75]\n",
      "  [651 707 314]]\n",
      "\n",
      " [[475 667 727]\n",
      "  [707 974 342]\n",
      "  [225 436  92]\n",
      "  [203 390 418]\n",
      "  [ 23 216 346]\n",
      "  [940 413 994]\n",
      "  [ 95 197 201]\n",
      "  [581 331  16]\n",
      "  [ 50 295 908]\n",
      "  [201 508 612]]\n",
      "\n",
      " [[870 675 516]\n",
      "  [198 863 471]\n",
      "  [248 205 846]\n",
      "  [833 231  54]\n",
      "  [970 532 622]\n",
      "  [900 541 965]\n",
      "  [639 598 340]\n",
      "  [159 448 283]\n",
      "  [657 941  82]\n",
      "  [439 684 232]]\n",
      "\n",
      " [[826 526  80]\n",
      "  [314 977 128]\n",
      "  [263 585 668]\n",
      "  [224 667 431]\n",
      "  [291 917 857]\n",
      "  [579 706 287]\n",
      "  [275 428 744]\n",
      "  [742  54 184]\n",
      "  [778 350 393]\n",
      "  [529 121 630]]\n",
      "\n",
      " [[409  34 722]\n",
      "  [733 791 404]\n",
      "  [ 49 270 306]\n",
      "  [413  17  21]\n",
      "  [926 686 928]\n",
      "  [726   5 118]\n",
      "  [758 356 329]\n",
      "  [366 324 778]\n",
      "  [392 776 446]\n",
      "  [390 666 712]]\n",
      "\n",
      " [[615 382 423]\n",
      "  [265  15 121]\n",
      "  [992 965 351]\n",
      "  [343 593  13]\n",
      "  [ 23 892 759]\n",
      "  [  8 906 672]\n",
      "  [424 120 973]\n",
      "  [766  93 496]\n",
      "  [177 936 865]\n",
      "  [268 315 173]]\n",
      "\n",
      " [[646  97 884]\n",
      "  [335 306 132]\n",
      "  [487 199  83]\n",
      "  [331 828 258]\n",
      "  [156 735 797]\n",
      "  [ 84 671  88]\n",
      "  [656 753 568]\n",
      "  [128 890 774]\n",
      "  [630 104 476]\n",
      "  [965 135 349]]\n",
      "\n",
      " [[649 331 964]\n",
      "  [465 539 302]\n",
      "  [565 451 889]\n",
      "  [131 466 918]\n",
      "  [237 776 757]\n",
      "  [ 10 190 565]\n",
      "  [447 734  69]\n",
      "  [ 90 517 546]\n",
      "  [149  14 876]\n",
      "  [431 296 502]]\n",
      "\n",
      " [[450 845 678]\n",
      "  [416 125 529]\n",
      "  [428 832  28]\n",
      "  [754 544 112]\n",
      "  [978  75 456]\n",
      "  [630 560 176]\n",
      "  [853 877 145]\n",
      "  [226 433 978]\n",
      "  [152 824 948]\n",
      "  [307  30 535]]\n",
      "\n",
      " [[914 248 684]\n",
      "  [259  34 380]\n",
      "  [228   5 853]\n",
      "  [581 333 302]\n",
      "  [463 954  20]\n",
      "  [ 38 682 688]\n",
      "  [624 418 257]\n",
      "  [563 195 428]\n",
      "  [ 55 479 314]\n",
      "  [398 618 756]]\n",
      "\n",
      " [[158 497 665]\n",
      "  [254 335  26]\n",
      "  [297 916 806]\n",
      "  [925  35 744]\n",
      "  [779  37 925]\n",
      "  [964 489 654]\n",
      "  [331 572 342]\n",
      "  [333  88 880]\n",
      "  [ 78 965 294]\n",
      "  [993 156 609]]\n",
      "\n",
      " [[ 19 205  96]\n",
      "  [498 955 667]\n",
      "  [ 42 914 428]\n",
      "  [238 985 262]\n",
      "  [597 461  86]\n",
      "  [349 871 997]\n",
      "  [876  44 802]\n",
      "  [554 387 999]\n",
      "  [  5 698 739]\n",
      "  [777 999 445]]\n",
      "\n",
      " [[318 619 120]\n",
      "  [903 510 855]\n",
      "  [677 253 204]\n",
      "  [464 344 512]\n",
      "  [513 597 913]\n",
      "  [862 643 403]\n",
      "  [104 527 446]\n",
      "  [813 399 651]\n",
      "  [144 515 596]\n",
      "  [232 696 280]]\n",
      "\n",
      " [[527 510 420]\n",
      "  [ 79 152 953]\n",
      "  [663 408 808]\n",
      "  [316 162 254]\n",
      "  [258 258 198]\n",
      "  [514 418 516]\n",
      "  [843 406 962]\n",
      "  [275 350 540]\n",
      "  [ 82 895  27]\n",
      "  [192 367 348]]\n",
      "\n",
      " [[775 879 523]\n",
      "  [833 353 797]\n",
      "  [586 796 303]\n",
      "  [583  35 218]\n",
      "  [947 145 147]\n",
      "  [297 901 657]\n",
      "  [807 438 774]\n",
      "  [ 85 375 822]\n",
      "  [355 381 542]\n",
      "  [466 920 652]]\n",
      "\n",
      " [[440  92 481]\n",
      "  [656 916 235]\n",
      "  [185 430  72]\n",
      "  [384 264 124]\n",
      "  [681 328 518]\n",
      "  [311 281 396]\n",
      "  [708  62 260]\n",
      "  [787 187 120]\n",
      "  [428 582  81]\n",
      "  [491 236 579]]\n",
      "\n",
      " [[182 937  17]\n",
      "  [214 235 540]\n",
      "  [417 336 165]\n",
      "  [214 581 912]\n",
      "  [745 435 755]\n",
      "  [460 963 515]\n",
      "  [606 577 375]\n",
      "  [589 660 739]\n",
      "  [620 724 450]\n",
      "  [938 160  12]]\n",
      "\n",
      " [[351 652 106]\n",
      "  [180 877 237]\n",
      "  [362 843 923]\n",
      "  [ 87 196 851]\n",
      "  [959 943 957]\n",
      "  [610 766 472]\n",
      "  [673 811 479]\n",
      "  [846 703 322]\n",
      "  [253   3 726]\n",
      "  [645 919 493]]]\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 426, in abstract_eval_fun\n",
      "    _, avals_out, _ = trace_to_jaxpr_dynamic(\n",
      "\n",
      "  File [...]/jax/_src/profiler.py, line 206, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 1620, in trace_to_jaxpr_dynamic\n",
      "    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 1657, in trace_to_subjaxpr_dynamic\n",
      "    ans = fun.call_wrapped(*in_tracers_)\n",
      "\n",
      "  File [...]/site-packages/jax/linear_util.py, line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "\n",
      "  File [...]/site-packages/jax/linear_util.py, line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "\n",
      "LayerError: Exception passing through layer  (in pure_fn):\n",
      "  layer created in file [...]/T/ipykernel_75043/461658037.py, line 2\n",
      "  layer input shapes: ShapeDtype{shape:(32, 10, 3), dtype:int32}\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 280, in forward\n",
      "    check_shape(x.shape, spec)\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 248, in check_shape\n",
      "    assert_equal(len(shape), len(spec))\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 244, in assert_equal\n",
      "    assert_true(a == b)\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 239, in assert_true\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: AssertShape Error. Expected ['bs'], got [(32, 10, 3)] with dict {}. Defined at /var/folders/27/8l0tbkzx7px4b1vn082g66qc0000gn/T/ipykernel_75043/3677967202.py:1 function input\n"
     ]
    }
   ],
   "source": [
    "X_ = np.random.randint(0, 1000, size=(32, 10, 3))\n",
    "model = EmbGRU(vocab_size=1000, d_feature=128, d_out=2)\n",
    "try:\n",
    "    model.init_weights_and_state(X_)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Implementing your own layers\n",
    "If we would like to implement our own layers, we could do that too.\n",
    "\n",
    "Again, from the [source code of trax](https://github.com/google/trax/blob/master/trax/layers/base.py#L747):\n",
    "\n",
    "```python\n",
    "def Fn(name, f, n_out=1):  # pylint: disable=invalid-name\n",
    "  \"\"\"Returns a layer with no weights that applies the function `f`.\n",
    "\n",
    "  `f` can take and return any number of arguments, and takes only positional\n",
    "  arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n",
    "  The following, for example, would create a layer that takes two inputs and\n",
    "  returns two outputs -- element-wise sums and maxima:\n",
    "\n",
    "      `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n",
    "\n",
    "  The layer's number of inputs (`n_in`) is automatically set to number of\n",
    "  positional arguments in `f`, but you must explicitly set the number of\n",
    "  outputs (`n_out`) whenever it's not the default value 1.\n",
    "\n",
    "  Args:\n",
    "    name: Class-like name for the resulting layer; for use in debugging.\n",
    "    f: Pure function from input tensors to output tensors, where each input\n",
    "        tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n",
    "        Output tensors must be packaged as specified in the `Layer` class\n",
    "        docstring.\n",
    "    n_out: Number of outputs promised by the layer; default value 1.\n",
    "\n",
    "  Returns:\n",
    "    Layer executing the function `f`.\n",
    "  \"\"\"\n",
    "  ```\n",
    "\n",
    "  Let's implement our own Hadamard product.\n",
    "  You might remember from the RNN lesson, that we used this for the gates:\n",
    "\n",
    "$$h_t = \\Gamma \\otimes h_{t-1}$$\n",
    "\n",
    "where $\\Gamma$ is the gate (which has the same size as $h$ and values between 0 and 1), $h$ is the hidden state, and $\\otimes$ the Hadamard product. For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.04 \\\\\n",
    "0.25 & -0.48\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.01 \\\\\n",
    "0.5 & 0.2\n",
    "\\end{bmatrix}\n",
    "\\otimes\n",
    "\\begin{bmatrix}\n",
    "1.0 & 2.0 \\\\\n",
    "0.5 & -2.4\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "X = np.random.rand(32, 20)\n",
    "\n",
    "# the gate is created with a softmax\n",
    "softmax = tl.Softmax(axis=-1)\n",
    "gate = softmax(X)\n",
    "\n",
    "# the gate is applied with a hadamard prodcut, implemented in numpy/jaxnumpy with `.multiply`\n",
    "out = jnp.multiply(X, gate)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jnp` function is kind of simple. But we want to make sure this is part of the backpropagation of our model.\n",
    "We make it into a proper layer with `tl.Fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hadamard():\n",
    "    def f(x0, x1):\n",
    "        return jnp.multiply(x0, x1)\n",
    "\n",
    "    return tl.Fn(\"Hadamard\", f, n_out=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use is as part of a model.\n",
    "For example, let's implement the Gated Linear Unit:\n",
    "$$GLU(X) = \\sigma(W_1 X + b_1) \\otimes (W_2 X + b_2)$$\n",
    "\n",
    "Let's break this down into smaller pieces:\n",
    "the gate is created with:\n",
    "$$gate(X) = \\sigma(W_1 X + b_1)$$\n",
    "\n",
    "and the input is branched into both the gate and a basic linear layer, then combined with a hadamard product.\n",
    "$$gate(X) \\otimes Linear(X)$$\n",
    "\n",
    "<img src=\"../../reports/figures/GLU.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 128), dtype:float32}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate = cb.Serial(tl.Dense(128), tl.Softmax(axis=-1))\n",
    "\n",
    "model = cb.Serial(\n",
    "    cb.Branch(gate, tl.Dense(128)),\n",
    "    Hadamard(),\n",
    ")\n",
    "model.init_weights_and_state(signature(X))\n",
    "yhat = model(X)\n",
    "signature(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, wrap it inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape(\"bd->bd\")\n",
    "def GLU(units: int):\n",
    "    gate = cb.Serial(tl.Dense(units), tl.Softmax(axis=-1))\n",
    "\n",
    "    model = cb.Serial(\n",
    "        cb.Branch(gate, tl.Dense(units)),\n",
    "        Hadamard(),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this notebook convinces you that:\n",
    "\n",
    "- Implementing PyTorch models we have built before in Trax is not that hard\n",
    "- Adding custom layers is pretty simple, once you figured out how to implement it in numpy/jaxnumpy. It helps that you will find numerous examples of numpy on the internet\n",
    "- Trax is really excellent for implementing parallel architectures, and it will save you a lot of code complexity\n",
    "- Building complex architectures can be done by recombining smaller units, a bit like building with LEGO.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
