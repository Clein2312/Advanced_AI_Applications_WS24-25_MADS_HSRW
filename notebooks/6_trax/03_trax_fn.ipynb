{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from trax import layers as tl\n",
    "from trax.shapes import signature\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.models.build import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Convolutions\n",
    "We can easily create new layers by combining the base layers from trax. You will find everything you know from torch.\n",
    "For example, a Conv2D layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 256, 256, 64), dtype:float32}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(32, 256, 256, 3)\n",
    "conv = tl.Conv(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"SAME\")\n",
    "conv.init_weights_and_state(signature(X))\n",
    "\n",
    "yhat = conv(X)\n",
    "signature(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a model with three serial Conv2d layers as we have built in the convolutions lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Conv                (32, 256, 256, 3)  (float64) | (32, 128, 128, 64) (float32)\n",
      "(1) Relu                (32, 128, 128, 64) (float32) | (32, 128, 128, 64) (float32)\n",
      "(2) Conv                (32, 128, 128, 64) (float32) | (32, 64, 64, 128)  (float32)\n",
      "(3) Relu                (32, 64, 64, 128)  (float32) | (32, 64, 64, 128)  (float32)\n",
      "(4) Conv                (32, 64, 64, 128)  (float32) | (32, 32, 32, 256)  (float32)\n",
      "(5) Relu                (32, 32, 32, 256)  (float32) | (32, 32, 32, 256)  (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 32, 32, 256), dtype:float32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cb.Serial(\n",
    "    tl.Conv(filters=64, kernel_size=(3,3), strides=(2,2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    "    tl.Conv(filters=128, kernel_size=(3,3), strides=(2,2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    "    tl.Conv(filters=256, kernel_size=(3,3), strides=(2,2), padding=\"SAME\"),\n",
    "    tl.Relu(),\n",
    ")\n",
    "model.init_weights_and_state(X)\n",
    "summary(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 RNNs\n",
    "Let's implement an Embedding + GRU + Linear model, like we built in the Attention lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_1000_128  (32, 100)          ( int64 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) Dense_2             (32, 100, 128)     (float32) | (32, 100, 2)       (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 100, 2), dtype:float32}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(0, 1000, size=(32, 100))\n",
    "\n",
    "model = cb.Serial(\n",
    "    tl.Embedding(vocab_size=1000, d_feature=128),\n",
    "    tl.GRU(n_units=128),\n",
    "    tl.Dense(2)\n",
    ")\n",
    "model.init_weights_and_state(signature(X))\n",
    "\n",
    "summary(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap this in a function, so we can pass the vocab_size and the units as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape('bs->bsd')\n",
    "def EmbGRU(vocab_size: int, d_feature: int, d_out: int):\n",
    "\n",
    "    model = cb.Serial(\n",
    "        tl.Embedding(vocab_size=vocab_size, d_feature=d_feature),\n",
    "        tl.GRU(n_units=d_feature),\n",
    "        tl.Dense(d_out)\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 The assert_shape decorator\n",
    "Note how we use an `@assert_shape` decorator. This is a very nice safety check.\n",
    "\n",
    "From the [trax source code](https://github.com/google/trax/blob/master/trax/layers/assert_shape.py#L70):\n",
    "\n",
    "```python\n",
    "  Examples:\n",
    "  # In Dense layer there is a single input and single output; the last dimension\n",
    "  # may change in size, while the sizes of all previous dimensions, marked by\n",
    "  # an ellipsis, will stay the same.\n",
    "  @assert_shape('...a->...b')\n",
    "  class Dense(base.Layer):\n",
    "    (...)\n",
    "\n",
    "  # DotProductCausalAttention takes three tensors as input: Queries, Keys, and\n",
    "  # Values, and outputs a single tensor. Sizes of the first two dimensions in\n",
    "  # all those tensors must match, while the last dimension must match only\n",
    "  # between Queries and Keys, and separately between Values and output tensor.\n",
    "  @assert_shape('blk,blk,bld->bld')\n",
    "  class DotProductCausalAttention(base.Layer):\n",
    "    (...)\n",
    "\n",
    "  # assert_shape can also be placed before the function returning base.Layer.\n",
    "  @assert_shape('...d->...')\n",
    "  def ReduceSum():\n",
    "    return Fn('ReduceSum', lambda x: jnp.sum(x, axis=-1, keepdims=False))\n",
    "```\n",
    "\n",
    "Our EmbGRU models expects as input a Tensor with dimensions (batch, sequencelenght) denoted with `bs`.\n",
    "The output should be (batch, sequencelenght, dimension) denoted with `bsd`.\n",
    "`@assert_shape` will check for us if this is correct.\n",
    "\n",
    "So this works:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n",
      "(0) Embedding_1000_128  (32, 100)          ( int64 ) | (32, 100, 128)     (float32)\n",
      "(1) GRU_128             (32, 100, 128)     (float32) | (32, 100, 128)     (float32)\n",
      "(2) Dense_2             (32, 100, 128)     (float32) | (32, 100, 2)       (float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 100, 2), dtype:float32}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EmbGRU(vocab_size=1000, d_feature=128, d_out=2)\n",
    "model.init_weights_and_state(signature(X))\n",
    "summary(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this fails! Can you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception passing through layer  (in _forward_abstract):\n",
      "  layer created in file [...]/T/ipykernel_95071/1363168418.py, line 2\n",
      "  layer input shapes: [[[691 843 671]\n",
      "  [  3 738 178]\n",
      "  [392 605 432]\n",
      "  [346 714 483]\n",
      "  [556 664 928]\n",
      "  [366  49 579]\n",
      "  [493 563 993]\n",
      "  [736 418 599]\n",
      "  [ 81 100  50]\n",
      "  [488 421 448]]\n",
      "\n",
      " [[523 889 227]\n",
      "  [528 514  46]\n",
      "  [495 214 271]\n",
      "  [457 234 916]\n",
      "  [389 156 881]\n",
      "  [464 524 231]\n",
      "  [857 703  71]\n",
      "  [  4 115 815]\n",
      "  [830 340 192]\n",
      "  [774 585 435]]\n",
      "\n",
      " [[784 933 481]\n",
      "  [182 682 769]\n",
      "  [530 392 896]\n",
      "  [448 255 285]\n",
      "  [907 120 907]\n",
      "  [146 613 319]\n",
      "  [457 378  41]\n",
      "  [332 144 795]\n",
      "  [ 16  71 878]\n",
      "  [503 982 823]]\n",
      "\n",
      " [[215 908 415]\n",
      "  [692  47 110]\n",
      "  [250 769 275]\n",
      "  [360  16 364]\n",
      "  [304 384  74]\n",
      "  [523 214 958]\n",
      "  [998 849 322]\n",
      "  [116 126  82]\n",
      "  [ 55 739  66]\n",
      "  [135 313 447]]\n",
      "\n",
      " [[607 343 187]\n",
      "  [263 368 619]\n",
      "  [382 152 872]\n",
      "  [553 871 644]\n",
      "  [699 366 249]\n",
      "  [ 88 296 230]\n",
      "  [178 401 501]\n",
      "  [938 616  46]\n",
      "  [382 937 444]\n",
      "  [458 673 998]]\n",
      "\n",
      " [[907 180 546]\n",
      "  [559 557 995]\n",
      "  [293 224 461]\n",
      "  [879 342 372]\n",
      "  [778 410 350]\n",
      "  [889 650 748]\n",
      "  [873 412 245]\n",
      "  [834 337 978]\n",
      "  [485 870 958]\n",
      "  [703 749 601]]\n",
      "\n",
      " [[289 542 954]\n",
      "  [557 865 461]\n",
      "  [686 370 676]\n",
      "  [535 172 576]\n",
      "  [961 922 391]\n",
      "  [994 512 974]\n",
      "  [820 551 436]\n",
      "  [899 569 292]\n",
      "  [694 122 667]\n",
      "  [323 828  12]]\n",
      "\n",
      " [[609 669 364]\n",
      "  [731 262  23]\n",
      "  [972 441 908]\n",
      "  [358 343 672]\n",
      "  [389 422 815]\n",
      "  [224 446  70]\n",
      "  [ 96 824 556]\n",
      "  [759 771 328]\n",
      "  [117 684 520]\n",
      "  [ 32 135 206]]\n",
      "\n",
      " [[941 918 430]\n",
      "  [ 36 120 250]\n",
      "  [298  89 650]\n",
      "  [139  30 167]\n",
      "  [986 370 286]\n",
      "  [173 152 127]\n",
      "  [955 815 174]\n",
      "  [967 214 551]\n",
      "  [ 79 186 529]\n",
      "  [586 529 646]]\n",
      "\n",
      " [[608 582 148]\n",
      "  [268 763 363]\n",
      "  [ 91 798 889]\n",
      "  [180 497 473]\n",
      "  [183 728 401]\n",
      "  [140   0  75]\n",
      "  [497 150 873]\n",
      "  [801 873 413]\n",
      "  [939  80 989]\n",
      "  [293 886 400]]\n",
      "\n",
      " [[ 91  98 533]\n",
      "  [ 34  12 367]\n",
      "  [411 178 114]\n",
      "  [ 85 692 131]\n",
      "  [976 742 680]\n",
      "  [480  31 228]\n",
      "  [240 744 666]\n",
      "  [954 405 565]\n",
      "  [654 899 268]\n",
      "  [431 983 288]]\n",
      "\n",
      " [[835 906 286]\n",
      "  [767 748 433]\n",
      "  [234 176 877]\n",
      "  [417 872  49]\n",
      "  [989 806 852]\n",
      "  [112 923 263]\n",
      "  [317 591  72]\n",
      "  [705 754 674]\n",
      "  [812 710 821]\n",
      "  [672 676 413]]\n",
      "\n",
      " [[869 861 269]\n",
      "  [745 404 426]\n",
      "  [313 938 260]\n",
      "  [995  17  32]\n",
      "  [472 167   9]\n",
      "  [947 120 162]\n",
      "  [754   4 847]\n",
      "  [262 162 101]\n",
      "  [579 956 967]\n",
      "  [333 885  15]]\n",
      "\n",
      " [[441 745   8]\n",
      "  [853 378 275]\n",
      "  [684 953 928]\n",
      "  [989 553 243]\n",
      "  [652 250 977]\n",
      "  [228   8 635]\n",
      "  [ 20 406 125]\n",
      "  [720 739 483]\n",
      "  [311 820  46]\n",
      "  [744 107 197]]\n",
      "\n",
      " [[462 932 448]\n",
      "  [302 912 246]\n",
      "  [335 698  50]\n",
      "  [107 591 165]\n",
      "  [317 499 736]\n",
      "  [431 516 427]\n",
      "  [995 129   3]\n",
      "  [742 659 797]\n",
      "  [989 745 280]\n",
      "  [478 698 694]]\n",
      "\n",
      " [[240 326  99]\n",
      "  [380 613 287]\n",
      "  [122 782 706]\n",
      "  [254 409 465]\n",
      "  [360 900  53]\n",
      "  [716  81 450]\n",
      "  [513 358 286]\n",
      "  [264 470 392]\n",
      "  [393  55 378]\n",
      "  [682 213 860]]\n",
      "\n",
      " [[917 284 810]\n",
      "  [304 449 573]\n",
      "  [861 417 597]\n",
      "  [910  61 197]\n",
      "  [662 850 667]\n",
      "  [ 89 270 338]\n",
      "  [997 211 755]\n",
      "  [372 633 861]\n",
      "  [742 737 140]\n",
      "  [573 918 335]]\n",
      "\n",
      " [[919 164 692]\n",
      "  [384 103 556]\n",
      "  [934  92 522]\n",
      "  [191 680 557]\n",
      "  [629 210 816]\n",
      "  [366 158 912]\n",
      "  [953 360 725]\n",
      "  [ 11 563 825]\n",
      "  [362 774 682]\n",
      "  [344 882 364]]\n",
      "\n",
      " [[410 397  94]\n",
      "  [110 572 915]\n",
      "  [389 966 928]\n",
      "  [803 649 302]\n",
      "  [363 541 158]\n",
      "  [987 862 452]\n",
      "  [474 268 343]\n",
      "  [443 184 270]\n",
      "  [298 704 626]\n",
      "  [418 585 695]]\n",
      "\n",
      " [[197 614 912]\n",
      "  [  9 394 961]\n",
      "  [613  10 273]\n",
      "  [ 56 850 830]\n",
      "  [333 614 244]\n",
      "  [288 711  29]\n",
      "  [485 141 364]\n",
      "  [204 712 489]\n",
      "  [765 749 239]\n",
      "  [921 684 398]]\n",
      "\n",
      " [[797 297 339]\n",
      "  [ 94 411 396]\n",
      "  [251 953 904]\n",
      "  [778 131  66]\n",
      "  [835 543 328]\n",
      "  [160 716 810]\n",
      "  [516  51 228]\n",
      "  [946 258 318]\n",
      "  [120 516 197]\n",
      "  [791 519  86]]\n",
      "\n",
      " [[112 400 615]\n",
      "  [587 173 477]\n",
      "  [962 687 737]\n",
      "  [652 243 570]\n",
      "  [385 616 533]\n",
      "  [776  13 481]\n",
      "  [487  28 421]\n",
      "  [536 710 439]\n",
      "  [425 749 594]\n",
      "  [ 62 235 735]]\n",
      "\n",
      " [[882 282 493]\n",
      "  [940 222 555]\n",
      "  [ 48 479 936]\n",
      "  [ 97 979 643]\n",
      "  [525 606 398]\n",
      "  [274 249 539]\n",
      "  [357 327  54]\n",
      "  [226  40  31]\n",
      "  [130 400 254]\n",
      "  [102 875 564]]\n",
      "\n",
      " [[141 771 135]\n",
      "  [341 315 162]\n",
      "  [676 387 127]\n",
      "  [791 285 114]\n",
      "  [746  74 505]\n",
      "  [793 372 340]\n",
      "  [263 777  85]\n",
      "  [246 200 763]\n",
      "  [997 691 822]\n",
      "  [612 558 782]]\n",
      "\n",
      " [[146 399 816]\n",
      "  [566 484 423]\n",
      "  [661 230 307]\n",
      "  [322 333 521]\n",
      "  [111  88 635]\n",
      "  [377 197 699]\n",
      "  [929 858 448]\n",
      "  [599 715 412]\n",
      "  [693 485 103]\n",
      "  [367 641 930]]\n",
      "\n",
      " [[854 294 980]\n",
      "  [ 61 450 542]\n",
      "  [731 426 774]\n",
      "  [644 258  63]\n",
      "  [584 551  86]\n",
      "  [  9 411 320]\n",
      "  [243 879 111]\n",
      "  [752 813 301]\n",
      "  [985 871 499]\n",
      "  [724 687 948]]\n",
      "\n",
      " [[696 185 995]\n",
      "  [627 358 282]\n",
      "  [ 43 956 717]\n",
      "  [106 164 921]\n",
      "  [171 279 915]\n",
      "  [720 622 256]\n",
      "  [ 35 458  59]\n",
      "  [518 508 374]\n",
      "  [627 246 489]\n",
      "  [407 221 431]]\n",
      "\n",
      " [[ 35 254  32]\n",
      "  [164 980 788]\n",
      "  [ 21 893 247]\n",
      "  [762 365 170]\n",
      "  [143  65 868]\n",
      "  [904 863 536]\n",
      "  [390 683 847]\n",
      "  [589 344 662]\n",
      "  [990 571 897]\n",
      "  [962 415 351]]\n",
      "\n",
      " [[291 950  74]\n",
      "  [866 538 905]\n",
      "  [388 947 216]\n",
      "  [313 676 118]\n",
      "  [998 968 676]\n",
      "  [794 516 955]\n",
      "  [434 968 569]\n",
      "  [264 531 166]\n",
      "  [775 652 540]\n",
      "  [347 430 210]]\n",
      "\n",
      " [[182 508 541]\n",
      "  [684 887 954]\n",
      "  [156 352 562]\n",
      "  [114 429 691]\n",
      "  [846 793 776]\n",
      "  [600 383 266]\n",
      "  [907 446 649]\n",
      "  [139 248 964]\n",
      "  [561 823 385]\n",
      "  [599 266 696]]\n",
      "\n",
      " [[ 17  67 716]\n",
      "  [347 919 351]\n",
      "  [453 745 118]\n",
      "  [646 549 516]\n",
      "  [611 373  56]\n",
      "  [365 740 126]\n",
      "  [692 405 844]\n",
      "  [330 313 597]\n",
      "  [967 345 452]\n",
      "  [720 946 857]]\n",
      "\n",
      " [[718 901 286]\n",
      "  [441 806  90]\n",
      "  [928 580 755]\n",
      "  [881 880  92]\n",
      "  [245 285 647]\n",
      "  [624 760 879]\n",
      "  [ 97 842 979]\n",
      "  [181 729 895]\n",
      "  [154  72 869]\n",
      "  [ 42 972 582]]]\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 426, in abstract_eval_fun\n",
      "    _, avals_out, _ = trace_to_jaxpr_dynamic(\n",
      "\n",
      "  File [...]/jax/_src/profiler.py, line 206, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 1620, in trace_to_jaxpr_dynamic\n",
      "    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(\n",
      "\n",
      "  File [...]/jax/interpreters/partial_eval.py, line 1657, in trace_to_subjaxpr_dynamic\n",
      "    ans = fun.call_wrapped(*in_tracers_)\n",
      "\n",
      "  File [...]/site-packages/jax/linear_util.py, line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "\n",
      "  File [...]/site-packages/jax/linear_util.py, line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "\n",
      "LayerError: Exception passing through layer  (in pure_fn):\n",
      "  layer created in file [...]/T/ipykernel_95071/1363168418.py, line 2\n",
      "  layer input shapes: ShapeDtype{shape:(32, 10, 3), dtype:int32}\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 280, in forward\n",
      "    check_shape(x.shape, spec)\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 248, in check_shape\n",
      "    assert_equal(len(shape), len(spec))\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 244, in assert_equal\n",
      "    assert_true(a == b)\n",
      "\n",
      "  File [...]/trax/layers/assert_shape.py, line 239, in assert_true\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: AssertShape Error. Expected ['bs'], got [(32, 10, 3)] with dict {}. Defined at /var/folders/27/8l0tbkzx7px4b1vn082g66qc0000gn/T/ipykernel_95071/756055733.py:1 function input\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(0, 1000, size=(32, 10, 3))\n",
    "model = EmbGRU(vocab_size=1000, d_feature=128)\n",
    "try:\n",
    "    model.init_weights_and_state(X)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Implementing your own layers\n",
    "If we would like to implement our own layers, we could do that too.\n",
    "\n",
    "Again, from the [source code of trax](https://github.com/google/trax/blob/master/trax/layers/base.py#L747):\n",
    "\n",
    "```python\n",
    "def Fn(name, f, n_out=1):  # pylint: disable=invalid-name\n",
    "  \"\"\"Returns a layer with no weights that applies the function `f`.\n",
    "\n",
    "  `f` can take and return any number of arguments, and takes only positional\n",
    "  arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n",
    "  The following, for example, would create a layer that takes two inputs and\n",
    "  returns two outputs -- element-wise sums and maxima:\n",
    "\n",
    "      `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n",
    "\n",
    "  The layer's number of inputs (`n_in`) is automatically set to number of\n",
    "  positional arguments in `f`, but you must explicitly set the number of\n",
    "  outputs (`n_out`) whenever it's not the default value 1.\n",
    "\n",
    "  Args:\n",
    "    name: Class-like name for the resulting layer; for use in debugging.\n",
    "    f: Pure function from input tensors to output tensors, where each input\n",
    "        tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n",
    "        Output tensors must be packaged as specified in the `Layer` class\n",
    "        docstring.\n",
    "    n_out: Number of outputs promised by the layer; default value 1.\n",
    "\n",
    "  Returns:\n",
    "    Layer executing the function `f`.\n",
    "  \"\"\"\n",
    "  ```\n",
    "\n",
    "  Let's implement our own Hadamard product.\n",
    "  You might remember from the RNN lesson, that we used this for the gates:\n",
    "\n",
    "$$h_t = \\Gamma \\otimes h_{t-1}$$\n",
    "\n",
    "where $\\Gamma$ is the gate (which has the same size as $h$ and values between 0 and 1), $h$ is the hidden state, and $\\otimes$ the Hadamard product. For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.04 \\\\\n",
    "0.25 & -0.48\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.01 \\\\\n",
    "0.5 & 0.2\n",
    "\\end{bmatrix}\n",
    "\\otimes\n",
    "\\begin{bmatrix}\n",
    "1.0 & 2.0 \\\\\n",
    "0.5 & -2.4\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = tl.Softmax(axis=-1)\n",
    "X = np.random.rand(32, 20)\n",
    "gate = softmax(X)\n",
    "\n",
    "out = jnp.multiply(X, gate)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jnp` function is kind of simple. But we want to make sure this is part of the backpropagation of our model.\n",
    "We make it into a proper layer with `tl.Fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hadamard():\n",
    "    def f(x0, x1):\n",
    "        return jnp.multiply(x0, x1)\n",
    "    \n",
    "    return tl.Fn(\"Hadamard\", f, n_out=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use is as part of a model.\n",
    "For example, let's implement the Gated Linear Unit:\n",
    "$$GLU(X) = \\sigma(W_1 X + b_1) \\otimes (W_2 X + b_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtype{shape:(32, 128), dtype:float32}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate = cb.Serial(\n",
    "    tl.Dense(128),\n",
    "    tl.Softmax(axis=-1)\n",
    ")\n",
    "\n",
    "model = cb.Serial(\n",
    "    cb.Branch(gate, tl.Dense(128)),\n",
    "    Hadamard(),\n",
    ")\n",
    "model.init_weights_and_state(signature(X))\n",
    "yhat = model(X)\n",
    "signature(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, wrap it inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape('bd->bd')\n",
    "def GLU(units: int):\n",
    "    gate = cb.Serial(\n",
    "    tl.Dense(units),\n",
    "    tl.Softmax(axis=-1)\n",
    "    )\n",
    "\n",
    "    model = cb.Serial(\n",
    "        cb.Branch(gate, tl.Dense(units)),\n",
    "        Hadamard(),\n",
    "    )\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
