{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /Users/rgrouls/code/ML22 to sys.path, this is necessary to import from src\n",
      "['/Users/rgrouls/code/ML22', '/Users/rgrouls/code/ML22/notebooks/4_tuning_networks', '/Users/rgrouls/.pyenv/versions/3.9.16/lib/python39.zip', '/Users/rgrouls/.pyenv/versions/3.9.16/lib/python3.9', '/Users/rgrouls/.pyenv/versions/3.9.16/lib/python3.9/lib-dynload', '', '/Users/rgrouls/Library/Caches/pypoetry/virtualenvs/deep-learning-HUU8cknU-py3.9/lib/python3.9/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "srcdir = Path(\"../..\").resolve()\n",
    "print(f\"Adding {srcdir} to sys.path, this is necessary to import from src\")\n",
    "sys.path.insert(0, str(srcdir))\n",
    "print(sys.path)\n",
    "\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit the flowers dataset from the first lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-06 11:38:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datasetfactory\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mDataset already exists at /Users/rgrouls/.cache/mads_datasets/flowers\u001b[0m\n",
      "\u001b[32m2023-06-06 11:38:31.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datasetfactory\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mDigest of downloaded /Users/rgrouls/.cache/mads_datasets/flowers/flowers.tgz matches expected digest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "flowersfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "streamers = flowersfactory.create_datastreamer(batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': BasetDatastreamer: ImgDataset (imgsize (224, 224), #classes 5) (streamerlen 91),\n",
       " 'valid': BasetDatastreamer: ImgDataset (imgsize (224, 224), #classes 5) (streamerlen 22)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FlowersDatasetFactory adds a transform function that will (at random) flip, scale, affine an image. For the model, this is a new image, so it needs to focus on the general patterns instead of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(trainstreamer)\n\u001b[1;32m      2\u001b[0m X\u001b[39m.\u001b[39mshape, y\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deep-learning-HUU8cknU-py3.9/lib/python3.9/site-packages/mads_datasets/datasetfactory.py:460\u001b[0m, in \u001b[0;36mBaseDatastreamer.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchloop()\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     X, Y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessor(batch)  \u001b[39m# noqa N806\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     X, Y \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)  \u001b[39m# noqa N806\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deep-learning-HUU8cknU-py3.9/lib/python3.9/site-packages/mads_datasets/datasetfactory.py:309\u001b[0m, in \u001b[0;36mBasePreprocessor.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, batch: List[Tuple]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    308\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[0;32m--> 309\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(X), torch\u001b[39m.\u001b[39mstack(y)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "X, y = next(trainstreamer)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m axs \u001b[39m=\u001b[39m axs\u001b[39m.\u001b[39mravel()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = X.permute(0, 2, 3, 1)\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10,10))\n",
    "axs = axs.ravel()\n",
    "for i in range(9):\n",
    "    axs[i].imshow(img[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the ranges, mean and std of a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.), tensor(0.3832), tensor(0.3007))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(), X.min(), X.mean(), X.std()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of building our own resnet, we will just download a pretrained version. This saves us many hours of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "resnet = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet18_Weights.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = resnet(X)\n",
    "yhat.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the resnet is trained for 1000 classes. We have just 5...\n",
    "\n",
    "We will swap the last layer and retrain the model.\n",
    "\n",
    "First, we freeze all pretrained layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you study the resnet implementation on [github](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L206) you can see that the last layer is named `.fc`, like this:\n",
    "\n",
    "```\n",
    " self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    " ```\n",
    "\n",
    "This is a Linear layer, mapping from 512 * block.expansion to num_classes.\n",
    "\n",
    "\n",
    "so we will swap that for our own. To do so we need to figure out how many features go into the .fc layer.\n",
    "We can retrieve the incoming amount of features for the current `.fc` with `.in_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(resnet.fc))\n",
    "in_features = resnet.fc.in_features\n",
    "in_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's swap that layer with a small, two layer, neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 5)\n",
    "    # nn.Linear(in_features, 128), nn.ReLU(), nn.Dropout(0.1), nn.Linear(128, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = resnet(X)\n",
    "yhat.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a fully trained resnet, but we added two layers at the end that transforms everything into 5 classes.\n",
    "These layers are random, so we need to train them for some epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take some time to train (about 4 min per epoch), you could scale down to amount of trainsteps to speed things up.\n",
    "\n",
    "You will start with a fairly high learning rate (0.01), and if the learning stops, after patience epochs the learning rate gets halved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.settings import TrainerSettings, ReportTypes\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellog\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    ")\n",
    "\n",
    "trainer = train_model.Trainer(\n",
    "    model=resnet, \n",
    "    settings=settings, \n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam, \n",
    "    traindataloader=trainstreamer, \n",
    "    validdataloader=validstreamer, \n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15911aab0965639e9482f052beb89e7ca291bb3f153727c5758e3fe9ad1321e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning-xB8KIJr7-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
